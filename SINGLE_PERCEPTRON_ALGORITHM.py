import numpy as np

# IMPLEMENTS THE A SINGLE PERCEPTRON ALGORITHM, WHERE THE REPRESENTATION OF EACH SAMPLE USES THE BAG OF WORDS MODEL. IN THIS MODEL, EACH SAMPLE IS REPRESENTED BY A VECTOR OF ABSOLUTE FREQUENCIES BASED ON A PREVIOUSLY DEFINED LEXICON.
class Perceptron:
    # INITIALIZE THE PERCEPTRON ALGORITHM.
    def __init__(self, T = 10):
        self.T = T # NUMBER OF ITERATIONS: T, IT'S THE HYPERPARAMETER THAT CORRESPONDS TO THE NUMBER OF ITERATIONS THAT THE ALGORITHM PASS THROUGH THE TRAINING DATA.
        self.THETA, self.THETA_0 = None, 0 # THETA IS A VECTOR OF WEIGHTS, THETA_0 IS THE BIAS (SCALAR).
    
    # TRAIN(): TRAINS THE MODEL; X REPRESENTS A VECTOR OF SAMPLES, Y REPRESENTS A VECTOR OF CORRESPONDING LABELS. EACH SAMPLE IS A DICIONARY WHERE THE KEY IS THE WORD AND THE VALUE IS THE ABSOLUTE FREQUENCY (COUNT) OF THE WORD IN THE SAMPLE.
    def TRAIN(self, X, Y):
        self.THETA = np.zeros(len(X[0])) # INITIALIZE THE WEIGHTS VECTOR WITH ZEROS.
        self.THETA_0 = 0 # INITIALIZE THE BIAS WITH ZERO.
        for _ in range(self.T): # FOR EACH ITERATION: T.
            for I in range(len(X)): # FOR EACH SAMPLE: X[I].
                if Y[I] * (np.dot(self.THETA, X[I]) + self.THETA_0) <= 0: # IF THE SAMPLE IS MISCLASSIFIED: UPDATE THE WEIGHTS AND THE BIAS.
                    self.THETA += (Y[I] * np.array(X[I])) # UPDATE THE WEIGHTS: THETA: THETA = THETA + Y[I] * X[I].
                    self.THETA_0 += Y[I] # UPDATE THE BIAS: THETA_0: THETA_0 = THETA_0 + Y[I].

    # CLASSIFY(): PREDICTS THE OUTPUT OF A SINGLE SAMPLE: X; SAMPLE IS A DICIONARY WHERE THE KEY IS THE WORD AND THE VALUE IS THE ABSOLUTE FREQUENCY (COUNT) OF THE WORD IN THE SAMPLE. RETURNS 1 IF SPAM, 0 IF HAM.
    def CLASSIFY(self, X):
        return np.sign(np.dot(self.THETA, X) + self.THETA_0) # CLASSIFY THE SAMPLE X USING THE WEIGHTS: THETA AND THE BIAS: THETA_0 STORED IN THE MODEL