import numpy as np

# THE `BIRCH_CLUSTERING` FUNCTION IMPLEMENTS THE BIRCH (BALANCED ITERATIVE REDUCING AND CLUSTERING USING HIERARCHIES) ALGORITHM, A HIERARCHICAL CLUSTERING ALGORITHM USED FOR LARGE-SCALE DATASETS.
#     1. THE FUNCTION TAKES THREE PARAMETERS: `X` (THE INPUT DATA), `BRANCHING_FACTOR` (THE MAXIMUM NUMBER OF CHILDREN FOR EACH INTERNAL NODE), AND AN OPTIONAL PARAMETER `THRESHOLD` (A THRESHOLD VALUE USED TO DETERMINE IF A NODE SHOULD BE SPLIT).
#     2. INSIDE THE FUNCTION, THERE IS A NESTED CLASS DEFINITION FOR `BIRCH_NODE`, WHICH REPRESENTS A NODE IN THE BIRCH TREE. EACH NODE HAS THE FOLLOWING ATTRIBUTES:
#         - `IS_LEAF`: A BOOLEAN FLAG INDICATING WHETHER THE NODE IS A LEAF NODE OR AN INTERNAL NODE.
#         - `CHILDREN`: A LIST OF CHILD NODES.
#         - `SUBCLUSTER_CENTERS`: A LIST OF SUBCLUSTER CENTERS ASSOCIATED WITH THE NODE.
#         - `N_SAMPLES`: THE NUMBER OF DATA POINTS IN THE SUBCLUSTERS ASSOCIATED WITH THE NODE.
#     3. THE `BIRCH_NODE` CLASS ALSO DEFINES SEVERAL METHODS:
#         - `ADD_CHILD(SELF, CHILD)`: ADDS A CHILD NODE TO THE CURRENT NODE.
#         - `IS_FULL(SELF)`: CHECKS IF THE CURRENT NODE HAS REACHED ITS MAXIMUM NUMBER OF CHILDREN.
#         - `SHOULD_SPLIT(SELF)`: CHECKS IF THE CURRENT NODE SHOULD BE SPLIT BASED ON THE THRESHOLD VALUE.
#         - `UPDATE_SUBCLUSTER_CENTERS(SELF, POINT)`: UPDATES THE SUBCLUSTER CENTERS ASSOCIATED WITH THE NODE BY ADDING A NEW POINT.
#         - `COMPUTE_PROTOTYPE(SELF)`: COMPUTES THE PROTOTYPE (CENTER) OF THE SUBCLUSTER CENTERS ASSOCIATED WITH THE NODE.
#     4. THE `__INSERT__` FUNCTION IS A RECURSIVE HELPER FUNCTION USED TO INSERT A DATA POINT INTO THE BIRCH TREE. IT TAKES A POINT `POINT` AND A NODE `NODE`. IF THE NODE IS A LEAF NODE, THE FUNCTION UPDATES THE SUBCLUSTER CENTERS OF THE NODE AND CHECKS IF THE NODE SHOULD BE SPLIT BASED ON THE THRESHOLD. IF THE NODE IS AN INTERNAL NODE, THE FUNCTION FINDS THE CLOSEST CHILD NODE TO THE POINT BASED ON THE DISTANCE TO THE CHILD'S PROTOTYPE AND RECURSIVELY CALLS `__INSERT__` WITH THE POINT AND THE CLOSEST CHILD.
#     5. THE `__SPLIT_NODE__` FUNCTION IS ANOTHER RECURSIVE HELPER FUNCTION USED TO SPLIT A NODE IF IT EXCEEDS THE THRESHOLD. IT TAKES A NODE `NODE` AS INPUT. THE FUNCTION CALCULATES A CHILD THRESHOLD BASED ON THE ORIGINAL THRESHOLD, CREATES A NEW LIST FOR SUBCLUSTER CENTERS FOR THE NODE, AND RESETS THE SAMPLE COUNT. THEN, FOR EACH SUBCLUSTER CENTER IN THE ORIGINAL LIST, THE FUNCTION FINDS THE CLOSEST CHILD NODE AND CHECKS IF THE DISTANCE IS GREATER THAN THE CHILD THRESHOLD. IF IT IS, A NEW NODE IS CREATED, THE SUBCLUSTER CENTER IS ADDED TO THE NEW NODE, AND THE NEW NODE IS ADDED AS A CHILD TO THE CURRENT NODE. OTHERWISE, THE SUBCLUSTER CENTER IS ADDED TO THE CLOSEST CHILD NODE. AFTER THIS PROCESS, THE PROTOTYPE OF EACH CHILD IS RECOMPUTED. IF THE CURRENT NODE IS NOW FULL, A NEW NODE IS CREATED, THE CHILDREN ARE MOVED TO THE NEW NODE, AND THE NEW NODE BECOMES THE ONLY CHILD OF THE CURRENT NODE.
#     6. THE `__FIND_CLOSEST_CLUSTER__` FUNCTION IS A RECURSIVE HELPER FUNCTION USED TO FIND THE CLOSEST CLUSTER CENTER TO A GIVEN POINT. IT TAKES A POINT `POINT` AND A NODE `NODE` AS INPUT. IF THE NODE IS A LEAF NODE, THE FUNCTION ITERATES OVER THE SUBCLUSTER CENTERS ASSOCIATED WITH THE NODE AND FINDS THE CLOSEST CENTER TO THE GIVEN POINT. IF THE NODE IS AN INTERNAL NODE, THE FUNCTION FINDS THE CLOSEST CHILD NODE BASED ON THE DISTANCE TO THE CHILD'S PROTOTYPE AND RECURSIVELY CALLS `__FIND_CLOSEST_CLUSTER__` WITH THE POINT AND THE CLOSEST CHILD.
#     7. THE MAIN PART OF THE `BIRCH_CLUSTERING` FUNCTION STARTS BY CREATING THE ROOT NODE OF THE BIRCH TREE.
#     8. IT THEN ITERATES OVER EACH POINT IN THE INPUT DATA `X` AND INSERTS THE POINT INTO THE BIRCH TREE USING THE `__INSERT__` FUNCTION.
#     9. AFTER INSERTING ALL THE POINTS, THE FUNCTION CREATES AN ARRAY `LABELS` TO STORE THE CLUSTER LABELS FOR EACH DATA POINT.
#     10. IT ITERATES OVER EACH DATA POINT AGAIN AND USES THE `__FIND_CLOSEST_CLUSTER__` FUNCTION TO FIND THE CLOSEST CLUSTER CENTER TO EACH POINT. THE LABEL OF THE CLOSEST CLUSTER CENTER IS ASSIGNED TO THE CORRESPONDING DATA POINT IN THE `LABELS` ARRAY.
#     11. FINALLY, THE `LABELS` ARRAY IS RETURNED AS THE RESULT OF THE `BIRCH_CLUSTERING` FUNCTION.
# IN SUMMARY, THE `BIRCH_CLUSTERING` FUNCTION IMPLEMENTS THE BIRCH ALGORITHM BY CONSTRUCTING A HIERARCHICAL TREE STRUCTURE, SPLITTING NODES IF THEY EXCEED A THRESHOLD, AND ASSIGNING CLUSTER LABELS TO DATA POINTS BASED ON THEIR PROXIMITY TO THE CLUSTER CENTERS. THE ALGORITHM PROVIDES A SCALABLE SOLUTION FOR CLUSTERING LARGE DATASETS.
def BIRCH_CLUSTERING(X, BRANCHING_FACTOR, THRESHOLD=0.5):
    """THE `BIRCH_CLUSTERING` FUNCTION IMPLEMENTS THE BIRCH (BALANCED ITERATIVE REDUCING AND CLUSTERING USING HIERARCHIES) ALGORITHM, A HIERARCHICAL CLUSTERING ALGORITHM SUITABLE FOR LARGE-SCALE DATASETS.
        1. BIRCH ALGORITHM OVERVIEW:
            - BIRCH IS A HIERARCHICAL CLUSTERING ALGORITHM THAT AIMS TO EFFICIENTLY CLUSTER LARGE DATASETS.
            - IT CONSTRUCTS A TREE-LIKE STRUCTURE CALLED THE BIRCH TREE, WHERE EACH NODE REPRESENTS A CLUSTER OR A SUBCLUSTER.
            - THE ALGORITHM INCREMENTALLY INSERTS DATA POINTS INTO THE TREE, DYNAMICALLY UPDATING THE CLUSTER STRUCTURE.
            - IT BALANCES THE TREE BY LIMITING THE NUMBER OF CHILDREN PER NODE AND SPLITTING NODES WHEN THEY EXCEED A THRESHOLD.
        2. BIRCH_NODE CLASS:
            - REPRESENTS A NODE IN THE BIRCH TREE.
            - TRACKS WHETHER THE NODE IS A LEAF NODE OR AN INTERNAL NODE.
            - STORES CHILD NODES, SUBCLUSTER CENTERS, AND THE NUMBER OF SAMPLES IN THE SUBCLUSTERS.
        3. INSERTION PROCESS:
            - THE ALGORITHM ITERATES THROUGH EACH DATA POINT AND INSERTS IT INTO THE BIRCH TREE.
            - THE POINT IS RECURSIVELY INSERTED INTO THE CLOSEST CHILD NODE BASED ON THE DISTANCE TO THE CHILD'S PROTOTYPE.
            - LEAF NODES UPDATE THEIR SUBCLUSTER CENTERS AND MAY SPLIT IF THEY EXCEED THE THRESHOLD.
        4. SPLITTING NODES:
            - WHEN A LEAF NODE EXCEEDS THE THRESHOLD, IT IS SPLIT INTO MULTIPLE CHILD NODES.
            - SUBCLUSTER CENTERS ASSOCIATED WITH THE ORIGINAL NODE ARE REDISTRIBUTED TO THE APPROPRIATE CHILD NODES.
            - IF A CHILD NODE CANNOT ACCOMMODATE A SUBCLUSTER CENTER, A NEW CHILD NODE IS CREATED.
            - THE PROTOTYPES (CENTERS) OF THE CHILD NODES ARE RECOMPUTED.
        5. FINDING THE CLOSEST CLUSTER:
            - TO ASSIGN CLUSTER LABELS, THE ALGORITHM FINDS THE CLOSEST CLUSTER CENTER TO EACH DATA POINT.
            - LEAF NODES COMPARE THE DISTANCES TO THEIR SUBCLUSTER CENTERS AND RETURN THE CLOSEST ONE.
            - INTERNAL NODES FIND THE CLOSEST CHILD NODE BASED ON THE DISTANCE TO THE CHILD'S PROTOTYPE AND RECURSE.
        6. LABEL ASSIGNMENT AND RESULT:
            - AFTER ALL DATA POINTS ARE INSERTED AND CLOSEST CLUSTERS ARE FOUND, CLUSTER LABELS ARE ASSIGNED.
            - AN ARRAY IS CREATED TO STORE THE CLUSTER LABELS FOR EACH DATA POINT.
            - EACH POINT IS ASSIGNED THE LABEL OF THE CLOSEST CLUSTER CENTER.
            - THE ARRAY OF LABELS IS RETURNED AS THE RESULT OF THE `BIRCH_CLUSTERING` FUNCTION.
    THE BIRCH ALGORITHM OFFERS AN EFFICIENT APPROACH TO CLUSTERING LARGE DATASETS, PROVIDING A HIERARCHICAL STRUCTURE THAT ALLOWS FOR SCALABILITY AND THE ABILITY TO HANDLE HIGH-DIMENSIONAL DATA."""

    # THE `BIRCH_NODE` CLASS IS A FUNDAMENTAL COMPONENT OF THE BIRCH CLUSTERING ALGORITHM. IT REPRESENTS A NODE IN THE BIRCH TREE AND MAINTAINS INFORMATION ABOUT THE CLUSTER OR SUBCLUSTER ASSOCIATED WITH THAT NODE.
    #     1. ATTRIBUTES:
    #         - `IS_LEAF`: THIS BOOLEAN ATTRIBUTE INDICATES WHETHER THE NODE IS A LEAF NODE OR AN INTERNAL NODE. LEAF NODES REPRESENT FINAL CLUSTERS, WHILE INTERNAL NODES REPRESENT INTERMEDIATE CLUSTERS OR SUBCLUSTERS.
    #         - `CHILDREN`: THIS ATTRIBUTE IS A LIST THAT STORES THE CHILD NODES OF THE CURRENT NODE. INTERNAL NODES HAVE CHILD NODES, WHEREAS LEAF NODES DO NOT.
    #         - `SUBCLUSTER_CENTERS`: THIS LIST CONTAINS THE SUBCLUSTER CENTERS ASSOCIATED WITH THE NODE. SUBCLUSTER CENTERS ARE REPRESENTATIVE POINTS WITHIN A CLUSTER OR SUBCLUSTER.
    #         - `N_SAMPLES`: THIS ATTRIBUTE KEEPS TRACK OF THE NUMBER OF DATA POINTS IN THE SUBCLUSTERS ASSOCIATED WITH THE NODE.
    #     2. METHODS:
    #         - `ADD_CHILD(SELF, CHILD)`: THIS METHOD ADDS A CHILD NODE TO THE CURRENT NODE. IT APPENDS THE CHILD NODE TO THE `CHILDREN` LIST.
    #         - `IS_FULL(SELF)`: THIS METHOD CHECKS IF THE CURRENT NODE HAS REACHED ITS MAXIMUM CAPACITY IN TERMS OF THE NUMBER OF CHILDREN IT CAN HAVE. IT RETURNS `TRUE` IF THE NUMBER OF CHILDREN EQUALS THE PREDEFINED BRANCHING FACTOR, `BRANCHING_FACTOR`, AND `FALSE` OTHERWISE.
    #         - `SHOULD_SPLIT(SELF)`: THIS METHOD DETERMINES WHETHER THE CURRENT NODE SHOULD BE SPLIT BASED ON THE NUMBER OF SAMPLES IT CONTAINS. IT COMPARES THE `N_SAMPLES` ATTRIBUTE WITH THE PREDEFINED THRESHOLD, `THRESHOLD`, AND RETURNS `TRUE` IF THE NUMBER OF SAMPLES EXCEEDS THE THRESHOLD, INDICATING THAT THE NODE SHOULD BE SPLIT.
    #         - `UPDATE_SUBCLUSTER_CENTERS(SELF, POINT)`: THIS METHOD UPDATES THE SUBCLUSTER CENTERS ASSOCIATED WITH THE NODE BY ADDING A NEW POINT. IT APPENDS THE `POINT` TO THE `SUBCLUSTER_CENTERS` LIST AND INCREMENTS THE `N_SAMPLES` ATTRIBUTE BY 1.
    #         - `COMPUTE_PROTOTYPE(SELF)`: THIS METHOD CALCULATES THE PROTOTYPE (CENTER) OF THE SUBCLUSTER CENTERS ASSOCIATED WITH THE NODE. IT CONVERTS THE `SUBCLUSTER_CENTERS` LIST INTO A NUMPY ARRAY, AND THEN COMPUTES THE MEAN OF THE SUBCLUSTER CENTERS ALONG EACH DIMENSION TO OBTAIN THE PROTOTYPE.
    # THE `BIRCH_NODE` CLASS ENCAPSULATES THE BEHAVIOR AND PROPERTIES OF INDIVIDUAL NODES IN THE BIRCH TREE. IT ALLOWS FOR THE ORGANIZATION OF DATA POINTS INTO CLUSTERS OR SUBCLUSTERS, TRACKING THEIR COUNTS AND REPRESENTATIVE CENTERS. THIS INFORMATION IS ESSENTIAL FOR THE INSERTION, SPLITTING, AND RETRIEVAL PROCESSES IN THE BIRCH ALGORITHM, FACILITATING THE CONSTRUCTION AND EXPLORATION OF THE HIERARCHICAL CLUSTERING STRUCTURE.
    class BIRCH_NODE:
        """THE `BIRCH_NODE` CLASS IS A FUNDAMENTAL COMPONENT OF THE BIRCH (BALANCED ITERATIVE REDUCING AND CLUSTERING USING HIERARCHIES) CLUSTERING ALGORITHM.
            1. ATTRIBUTES:
                - `IS_LEAF`: A BOOLEAN FLAG INDICATING WHETHER THE NODE IS A LEAF NODE OR AN INTERNAL NODE.
                - `CHILDREN`: A LIST STORING THE CHILD NODES OF THE CURRENT NODE.
                - `SUBCLUSTER_CENTERS`: A LIST OF SUBCLUSTER CENTERS ASSOCIATED WITH THE NODE.
                - `N_SAMPLES`: THE NUMBER OF DATA POINTS IN THE SUBCLUSTERS ASSOCIATED WITH THE NODE.
            2. `ADD_CHILD` METHOD: ADDS A CHILD NODE TO THE CURRENT NODE BY APPENDING IT TO THE `CHILDREN` LIST.
            3. `IS_FULL` METHOD: CHECKS IF THE CURRENT NODE HAS REACHED ITS MAXIMUM CAPACITY BY COMPARING THE NUMBER OF CHILDREN WITH THE PREDEFINED BRANCHING FACTOR.
            4. `SHOULD_SPLIT` METHOD: DETERMINES IF THE CURRENT NODE SHOULD BE SPLIT BASED ON THE NUMBER OF SAMPLES IT CONTAINS, COMPARING IT WITH THE PREDEFINED THRESHOLD.
            5. `UPDATE_SUBCLUSTER_CENTERS` METHOD:
                - UPDATES THE SUBCLUSTER CENTERS ASSOCIATED WITH THE NODE BY ADDING A NEW POINT TO THE `SUBCLUSTER_CENTERS` LIST.
                - INCREMENTS THE `N_SAMPLES` ATTRIBUTE TO REFLECT THE ADDITION OF A NEW DATA POINT.
            6. `COMPUTE_PROTOTYPE` METHOD:
                - CALCULATES THE PROTOTYPE (CENTER) OF THE SUBCLUSTER CENTERS ASSOCIATED WITH THE NODE.
                - CONVERTS THE `SUBCLUSTER_CENTERS` LIST INTO A NUMPY ARRAY AND COMPUTES THE MEAN ALONG EACH DIMENSION TO OBTAIN THE PROTOTYPE.
        THE `BIRCH_NODE` CLASS PLAYS A CRUCIAL ROLE IN MAINTAINING THE HIERARCHICAL STRUCTURE OF THE BIRCH TREE. IT STORES INFORMATION ABOUT WHETHER A NODE IS A LEAF OR INTERNAL NODE, KEEPS TRACK OF CHILD NODES, SUBCLUSTER CENTERS, AND THE NUMBER OF DATA POINTS IN EACH SUBCLUSTER. THESE ATTRIBUTES AND METHODS ENABLE THE CONSTRUCTION, SPLITTING, AND MANAGEMENT OF CLUSTERS AND SUBCLUSTERS WITHIN THE BIRCH ALGORITHM."""

        def __init__(self, IS_LEAF=True):
            self.IS_LEAF = IS_LEAF
            self.CHILDREN = []
            self.SUBCLUSTER_CENTERS = []
            self.N_SAMPLES = 0

        def ADD_CHILD(self, CHILD):
            self.CHILDREN.append(CHILD)

        def IS_FULL(self):
            return len(self.CHILDREN) == BRANCHING_FACTOR

        def SHOULD_SPLIT(self):
            return self.N_SAMPLES > THRESHOLD

        def UPDATE_SUBCLUSTER_CENTERS(self, POINT):
            self.SUBCLUSTER_CENTERS.append(POINT)
            self.N_SAMPLES += 1

        def COMPUTE_PROTOTYPE(self):
            self.SUBCLUSTER_CENTERS = np.array(self.SUBCLUSTER_CENTERS)
            self.PROTOTYPE = np.mean(self.SUBCLUSTER_CENTERS, axis=0)

    def __INSERT__(POINT, NODE):
        if NODE.IS_LEAF:
            NODE.UPDATE_SUBCLUSTER_CENTERS(POINT)
            if NODE.SHOULD_SPLIT():
                __SPLIT_NODE__(NODE)
        else:
            MIN_DISTANCE = float('inf')
            CLOSEST_CHILD = None
            for CHILD in NODE.CHILDREN:
                DISTANCE = np.linalg.norm(POINT - CHILD.PROTOTYPE)
                if DISTANCE < MIN_DISTANCE:
                    MIN_DISTANCE = DISTANCE
                    CLOSEST_CHILD = CHILD
            __INSERT__(POINT, CLOSEST_CHILD)

    def __SPLIT_NODE__(NODE):
        CHILD_THRESHOLD = THRESHOLD / 2
        SUBCLUSTER_CENTERS = NODE.SUBCLUSTER_CENTERS
        NODE.SUBCLUSTER_CENTERS = []
        NODE.N_SAMPLES = 0
        for SUBCLUSTER_CENTER in SUBCLUSTER_CENTERS:
            MIN_DISTANCE = float('inf')
            CLOSEST_CHILD = None
            for CHILD in NODE.CHILDREN:
                DISTANCE = np.linalg.norm(SUBCLUSTER_CENTER - CHILD.PROTOTYPE)
                if DISTANCE < MIN_DISTANCE:
                    MIN_DISTANCE = DISTANCE
                    CLOSEST_CHILD = CHILD
            if CLOSEST_CHILD is None or MIN_DISTANCE > CHILD_THRESHOLD:
                NEW_NODE = BIRCH_NODE()
                NEW_NODE.UPDATE_SUBCLUSTER_CENTERS(SUBCLUSTER_CENTER)
                NODE.ADD_CHILD(NEW_NODE)
            else:
                CLOSEST_CHILD.UPDATE_SUBCLUSTER_CENTERS(SUBCLUSTER_CENTER)
        for CHILD in NODE.CHILDREN:
            CHILD.COMPUTE_PROTOTYPE()
        if NODE.IS_FULL():
            NEW_NODE = BIRCH_NODE(False)
            NEW_NODE.CHILDREN = NODE.CHILDREN
            NODE.CHILDREN = [NEW_NODE]

    def __FIND_CLOSEST_CLUSTER__(POINT, NODE):
        if NODE.IS_LEAF:
            MIN_DISTANCE = float('inf')
            CLOSEST_CLUSTER = None
            for SUBCLUSTER_CENTER in NODE.SUBCLUSTER_CENTERS:
                DISTANCE = np.linalg.norm(POINT - SUBCLUSTER_CENTER)
                if DISTANCE < MIN_DISTANCE:
                    MIN_DISTANCE = DISTANCE
                    CLOSEST_CLUSTER = SUBCLUSTER_CENTER
            return CLOSEST_CLUSTER
        else:
            MIN_DISTANCE = float('inf')
            CLOSEST_CHILD = None
            for CHILD in NODE.CHILDREN:
                DISTANCE = np.linalg.norm(POINT - CHILD.PROTOTYPE)
                if DISTANCE < MIN_DISTANCE:
                    MIN_DISTANCE = DISTANCE
                    CLOSEST_CHILD = CHILD
            return __FIND_CLOSEST_CLUSTER__(POINT, CLOSEST_CHILD)
    
    ROOT = BIRCH_NODE()
    for POINT in X:
        __INSERT__(POINT, ROOT)
    LABELS = np.zeros(len(X))
    for i, POINT in enumerate(X):
        LABELS[i] = __FIND_CLOSEST_CLUSTER__(POINT, ROOT)
    return LABELS