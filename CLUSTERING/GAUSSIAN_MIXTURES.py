import numpy as np

def GAUSSIAN_MIXTURES(X, K=2, MAX_ITERATIONS=100, TOLERANCE=1e-4):

    def __ESTIMATE_RESPONSIBILITIES__(X, WEIGHTS, MEANS, COVARIANCES):
        N_SAMPLES = X.shape[0]
        K = WEIGHTS.shape[0]
        WEIGHTED_DENSITIES = np.zeros((N_SAMPLES, K))
        for i in range(K):
            WEIGHTED_DENSITIES[:, i] = WEIGHTS[i] * __MULTIVARIATE_NORMAL__(X, MEANS[i], COVARIANCES[i])
        RESPONSIBILITY_MATRIX = WEIGHTED_DENSITIES / np.sum(WEIGHTED_DENSITIES, axis=1, keepdims=True)
        return RESPONSIBILITY_MATRIX

    def __ESTIMATE_PARAMETERS__(X, RESPONSIBILITY_MATRIX):
        N_SAMPLES, N_FEATURES = X.shape
        K = RESPONSIBILITY_MATRIX.shape[1]
        RESPONSIBILITY_MATRIX_sum = np.sum(RESPONSIBILITY_MATRIX, axis=0)
        WEIGHTS = RESPONSIBILITY_MATRIX_sum / N_SAMPLES
        MEANS = np.dot(RESPONSIBILITY_MATRIX.T, X) / RESPONSIBILITY_MATRIX_sum[:, np.newaxis]
        COVARIANCES = []
        for i in range(K):
            DIFFERENCE = X - MEANS[i]
            WEIGHTED_DIFFERENCE = RESPONSIBILITY_MATRIX[:, i][:, np.newaxis] * DIFFERENCE
            COVARIANCES.append(np.dot(WEIGHTED_DIFFERENCE.T, DIFFERENCE) / RESPONSIBILITY_MATRIX_sum[i])
        COVARIANCES = np.array(COVARIANCES)
        return WEIGHTS, MEANS, COVARIANCES

    def __MULTIVARIATE_NORMAL__(X, MEAN, COVARIANCE_MATRIX):
        K = X.shape[1]
        DETERMINANT = np.linalg.det(COVARIANCE_MATRIX)
        NORMALIZATION_CONSTANT = 1.0 / ((2 * np.pi) ** (K / 2) * np.sqrt(DETERMINANT))
        INVERSE_OF_COVARIANCE_MATRIX = np.linalg.inv(COVARIANCE_MATRIX)
        EXPONENT = -0.5 * np.sum(np.dot((X - MEAN), INVERSE_OF_COVARIANCE_MATRIX) * (X - MEAN), axis=1)
        return NORMALIZATION_CONSTANT * np.exp(EXPONENT)

    def __LOG_LIKELIHOOD__(X, WEIGHTS, MEANS, COVARIANCES):
        LOG_LIKELIHOODS = np.log(np.sum([WEIGHTS[i] * __MULTIVARIATE_NORMAL__(X, MEANS[i], COVARIANCES[i]) for i in range(WEIGHTS.shape[0])], axis=0))
        return np.sum(LOG_LIKELIHOODS)

    N_SAMPLES, N_FEATURES = X.shape
    WEIGHTS = np.ones(K) / K
    MEANS = X[np.random.choice(N_SAMPLES, K, replace=False)]
    COVARIANCES = np.array([np.eye(N_FEATURES)] * K)
    PREVIOUS_LOG_LIKELIHOOD = 0.0
    for _ in range(MAX_ITERATIONS):
        RESPONSIBILITY_MATRIX = __ESTIMATE_RESPONSIBILITIES__(X, WEIGHTS, MEANS, COVARIANCES)
        WEIGHTS, MEANS, COVARIANCES = __ESTIMATE_PARAMETERS__(X, RESPONSIBILITY_MATRIX)
        LOG_LIKELIHOOD = __LOG_LIKELIHOOD__(X, WEIGHTS, MEANS, COVARIANCES)
        if np.abs(LOG_LIKELIHOOD - PREVIOUS_LOG_LIKELIHOOD) < TOLERANCE:
            break
        PREVIOUS_LOG_LIKELIHOOD = LOG_LIKELIHOOD
    RESPONSIBILITY_MATRIX = __ESTIMATE_RESPONSIBILITIES__(X, WEIGHTS, MEANS, COVARIANCES)
    LABELS = np.argmax(RESPONSIBILITY_MATRIX, axis=1)
    return LABELS