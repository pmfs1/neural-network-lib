import numpy as np

# THE `GAUSSIAN_MIXTURES` FUNCTION IS AN IMPLEMENTATION OF THE GAUSSIAN MIXTURE MODEL (GMM) ALGORITHM. GMM IS A PROBABILISTIC MODEL THAT REPRESENTS A MIXTURE OF GAUSSIAN DISTRIBUTIONS. IT IS COMMONLY USED FOR CLUSTERING AND DENSITY ESTIMATION TASKS.
#     1. THE FUNCTION TAKES THE FOLLOWING INPUTS:
#         - `X`: THE INPUT DATA, REPRESENTED AS A NUMPY ARRAY. EACH ROW IN `X` CORRESPONDS TO A DATA SAMPLE, AND EACH COLUMN REPRESENTS A FEATURE.
#         - `K`: THE NUMBER OF GAUSSIAN COMPONENTS OR CLUSTERS TO BE ESTIMATED. THIS IS AN OPTIONAL PARAMETER, AND ITS DEFAULT VALUE IS 2.
#         - `MAX_ITERATIONS`: THE MAXIMUM NUMBER OF ITERATIONS FOR THE ALGORITHM. THIS IS AN OPTIONAL PARAMETER, AND ITS DEFAULT VALUE IS 100.
#         - `TOLERANCE`: THE TOLERANCE VALUE THAT DETERMINES THE CONVERGENCE OF THE ALGORITHM. IF THE CHANGE IN LOG-LIKELIHOOD BETWEEN CONSECUTIVE ITERATIONS IS LESS THAN THIS VALUE, THE ALGORITHM STOPS. THIS IS AN OPTIONAL PARAMETER, AND ITS DEFAULT VALUE IS 1E-4.
#     2. THE FUNCTION DEFINES SEVERAL HELPER FUNCTIONS WITHIN ITS SCOPE:
#         - `__ESTIMATE_RESPONSIBILITIES__`: THIS FUNCTION COMPUTES THE RESPONSIBILITIES, WHICH REPRESENT THE PROBABILITIES THAT EACH DATA SAMPLE BELONGS TO EACH GAUSSIAN COMPONENT. IT TAKES THE INPUT DATA `X`, THE WEIGHTS OF THE GAUSSIAN COMPONENTS, THE MEANS OF THE COMPONENTS, AND THE COVARIANCE MATRICES OF THE COMPONENTS AS INPUTS. IT RETURNS A RESPONSIBILITY MATRIX.
#         - `__ESTIMATE_PARAMETERS__`: THIS FUNCTION ESTIMATES THE PARAMETERS OF THE GAUSSIAN COMPONENTS BASED ON THE RESPONSIBILITY MATRIX. IT TAKES THE INPUT DATA `X` AND THE RESPONSIBILITY MATRIX AS INPUTS. IT RETURNS UPDATED WEIGHTS, MEANS, AND COVARIANCE MATRICES FOR EACH COMPONENT.
#         - `__MULTIVARIATE_NORMAL__`: THIS FUNCTION COMPUTES THE MULTIVARIATE NORMAL DISTRIBUTION FOR A GIVEN DATA SAMPLE, MEAN, AND COVARIANCE MATRIX. IT TAKES THE INPUT DATA `X`, THE MEAN OF THE COMPONENT, AND THE COVARIANCE MATRIX OF THE COMPONENT AS INPUTS. IT RETURNS THE PROBABILITY DENSITY OF THE MULTIVARIATE NORMAL DISTRIBUTION FOR EACH DATA SAMPLE.
#         - `__LOG_LIKELIHOOD__`: THIS FUNCTION COMPUTES THE LOG-LIKELIHOOD OF THE GMM GIVEN THE CURRENT PARAMETERS. IT TAKES THE INPUT DATA `X`, THE WEIGHTS OF THE GAUSSIAN COMPONENTS, THE MEANS OF THE COMPONENTS, AND THE COVARIANCE MATRICES OF THE COMPONENTS AS INPUTS. IT RETURNS THE LOG-LIKELIHOOD VALUE.
#     3. THE FUNCTION INITIALIZES THE PARAMETERS OF THE GMM:
#         - `N_SAMPLES` AND `N_FEATURES` STORE THE NUMBER OF SAMPLES AND FEATURES IN THE INPUT DATA, RESPECTIVELY.
#         - `WEIGHTS` IS INITIALIZED AS A UNIFORM DISTRIBUTION, WHERE EACH COMPONENT HAS EQUAL WEIGHT.
#         - `MEANS` ARE RANDOMLY CHOSEN FROM THE INPUT DATA, WITHOUT REPLACEMENT.
#         - `COVARIANCES` ARE INITIALIZED AS IDENTITY MATRICES FOR EACH COMPONENT.
#     4. THE FUNCTION ITERATIVELY UPDATES THE PARAMETERS OF THE GMM UNTIL CONVERGENCE OR UNTIL REACHING THE MAXIMUM NUMBER OF ITERATIONS:
#         - IT FIRST COMPUTES THE RESPONSIBILITY MATRIX USING THE CURRENT PARAMETERS.
#         - THEN, IT UPDATES THE WEIGHTS, MEANS, AND COVARIANCES BASED ON THE RESPONSIBILITY MATRIX USING THE `__ESTIMATE_PARAMETERS__` FUNCTION.
#         - THE LOG-LIKELIHOOD OF THE GMM IS COMPUTED USING THE UPDATED PARAMETERS.
#         - IF THE ABSOLUTE DIFFERENCE BETWEEN THE CURRENT LOG-LIKELIHOOD AND THE PREVIOUS LOG-LIKELIHOOD IS SMALLER THAN THE TOLERANCE, THE ALGORITHM STOPS.
#         - OTHERWISE, THE CURRENT LOG-LIKELIHOOD BECOMES THE PREVIOUS LOG-LIKELIHOOD, AND THE ITERATION CONTINUES.
#     5. AFTER CONVERGENCE OR REACHING THE MAXIMUM NUMBER OF ITERATIONS, THE FINAL RESPONSIBILITY MATRIX IS COMPUTED USING THE UPDATED PARAMETERS.
#     6. THE FUNCTION ASSIGNS LABELS TO THE DATA SAMPLES BASED ON THE MAXIMUM PROBABILITY IN THE RESPONSIBILITY MATRIX.
#     7. FINALLY, THE FUNCTION RETURNS THE LABELS ASSIGNED TO EACH DATA SAMPLE.
# IN SUMMARY, THE `GAUSSIAN_MIXTURES` FUNCTION IMPLEMENTS THE GAUSSIAN MIXTURE MODEL ALGORITHM TO ESTIMATE A SPECIFIED NUMBER OF GAUSSIAN COMPONENTS FROM THE INPUT DATA. IT ITERATIVELY UPDATES THE PARAMETERS OF THE MODEL UNTIL CONVERGENCE AND RETURNS THE ASSIGNED LABELS FOR EACH DATA SAMPLE.
def GAUSSIAN_MIXTURES(X, K=2, MAX_ITERATIONS=100, TOLERANCE=1e-4):
    """THE `GAUSSIAN_MIXTURES` FUNCTION IS AN IMPLEMENTATION OF THE GAUSSIAN MIXTURE MODEL (GMM) ALGORITHM, WHICH IS USED FOR CLUSTERING AND DENSITY ESTIMATION TASKS.
        - INPUTS:
            - `X`: THE INPUT DATA REPRESENTED AS A NUMPY ARRAY, WHERE EACH ROW CORRESPONDS TO A DATA SAMPLE AND EACH COLUMN REPRESENTS A FEATURE.
            - `K` (OPTIONAL): THE NUMBER OF GAUSSIAN COMPONENTS OR CLUSTERS TO BE ESTIMATED. DEFAULT VALUE IS 2.
            - `MAX_ITERATIONS` (OPTIONAL): THE MAXIMUM NUMBER OF ITERATIONS FOR THE ALGORITHM. DEFAULT VALUE IS 100.
            - `TOLERANCE` (OPTIONAL): THE CONVERGENCE TOLERANCE FOR THE ALGORITHM. DEFAULT VALUE IS 1E-4.
        - STEPS:
            1. INITIALIZE PARAMETERS: INITIALIZE THE WEIGHTS, MEANS, AND COVARIANCES OF THE GAUSSIAN COMPONENTS.
            2. HELPER FUNCTIONS: DEFINE FUNCTIONS TO COMPUTE RESPONSIBILITIES, ESTIMATE PARAMETERS, COMPUTE MULTIVARIATE NORMAL DISTRIBUTIONS, AND CALCULATE LOG-LIKELIHOOD.
            3. ITERATIVE UPDATES: ITERATIVELY UPDATE THE PARAMETERS OF THE GMM UNTIL CONVERGENCE OR REACHING THE MAXIMUM NUMBER OF ITERATIONS.
                - COMPUTE RESPONSIBILITIES BASED ON CURRENT PARAMETERS.
                - UPDATE WEIGHTS, MEANS, AND COVARIANCES USING THE RESPONSIBILITY MATRIX.
                - COMPUTE THE LOG-LIKELIHOOD OF THE GMM.
                - CHECK FOR CONVERGENCE USING THE LOG-LIKELIHOOD AND THE TOLERANCE VALUE.
            4. COMPUTE FINAL RESPONSIBILITIES: COMPUTE THE RESPONSIBILITY MATRIX USING THE UPDATED PARAMETERS.
            5. ASSIGN LABELS: ASSIGN LABELS TO THE DATA SAMPLES BASED ON THE MAXIMUM PROBABILITY IN THE RESPONSIBILITY MATRIX.
            6. OUTPUT: RETURN THE ASSIGNED LABELS FOR EACH DATA SAMPLE.
        - SUMMARY: THE `GAUSSIAN_MIXTURES` FUNCTION USES THE GMM ALGORITHM TO ESTIMATE GAUSSIAN COMPONENTS FROM INPUT DATA. IT ITERATIVELY UPDATES THE PARAMETERS UNTIL CONVERGENCE, COMPUTES THE RESPONSIBILITIES, AND ASSIGNS LABELS TO THE DATA SAMPLES."""

    # THE `__ESTIMATE_RESPONSIBILITIES__` FUNCTION IS A HELPER FUNCTION WITHIN THE `GAUSSIAN_MIXTURES` FUNCTION. ITS PURPOSE IS TO COMPUTE THE RESPONSIBILITIES, WHICH REPRESENT THE PROBABILITIES THAT EACH DATA SAMPLE BELONGS TO EACH GAUSSIAN COMPONENT.
    #     1. INPUTS:
    #         - `X`: THE INPUT DATA REPRESENTED AS A NUMPY ARRAY.
    #         - `WEIGHTS`: THE WEIGHTS OF THE GAUSSIAN COMPONENTS.
    #         - `MEANS`: THE MEANS OF THE GAUSSIAN COMPONENTS.
    #         - `COVARIANCES`: THE COVARIANCE MATRICES OF THE GAUSSIAN COMPONENTS.
    #     2. THE FUNCTION BEGINS BY EXTRACTING THE NUMBER OF SAMPLES (`N_SAMPLES`) FROM THE INPUT DATA `X` AND THE NUMBER OF GAUSSIAN COMPONENTS (`K`) FROM THE SHAPE OF THE `WEIGHTS` ARRAY.
    #     3. IT CREATES AN EMPTY ARRAY CALLED `WEIGHTED_DENSITIES` WITH THE SHAPE `(N_SAMPLES, K)` TO STORE THE WEIGHTED DENSITIES OF EACH DATA SAMPLE FOR EACH COMPONENT.
    #     4. THE FUNCTION THEN ITERATES OVER EACH GAUSSIAN COMPONENT USING A `FOR` LOOP AND COMPUTES THE WEIGHTED DENSITIES. FOR EACH COMPONENT `I`:
    #         - IT MULTIPLIES THE WEIGHT OF THE COMPONENT (`WEIGHTS[I]`) WITH THE DENSITY OF THE DATA SAMPLES BASED ON A MULTIVARIATE NORMAL DISTRIBUTION. THIS IS DONE BY CALLING THE `__MULTIVARIATE_NORMAL__` FUNCTION, PASSING THE INPUT DATA `X`, THE MEAN OF THE COMPONENT (`MEANS[I]`), AND THE COVARIANCE MATRIX OF THE COMPONENT (`COVARIANCES[I]`).
    #         - THE RESULTING WEIGHTED DENSITIES ARE STORED IN THE `WEIGHTED_DENSITIES` ARRAY.
    #     5. NEXT, THE FUNCTION COMPUTES THE RESPONSIBILITY MATRIX BY NORMALIZING THE WEIGHTED DENSITIES. IT DIVIDES EACH WEIGHTED DENSITY VALUE BY THE SUM OF WEIGHTED DENSITIES ACROSS ALL COMPONENTS FOR THE CORRESPONDING DATA SAMPLE. THIS NORMALIZATION STEP ENSURES THAT THE RESPONSIBILITIES SUM UP TO 1 FOR EACH DATA SAMPLE.
    #         - THE DIVISION IS PERFORMED USING `NP.SUM(WEIGHTED_DENSITIES, AXIS=1, KEEPDIMS=TRUE)` TO CALCULATE THE SUM OF WEIGHTED DENSITIES FOR EACH DATA SAMPLE.
    #         - THE RESULTING RESPONSIBILITY MATRIX IS STORED IN THE VARIABLE `RESPONSIBILITY_MATRIX`.
    #     6. FINALLY, THE FUNCTION RETURNS THE RESPONSIBILITY MATRIX.
    # IN SUMMARY, THE `__ESTIMATE_RESPONSIBILITIES__` FUNCTION COMPUTES THE RESPONSIBILITIES, REPRESENTING THE PROBABILITIES THAT EACH DATA SAMPLE BELONGS TO EACH GAUSSIAN COMPONENT. IT ITERATES OVER THE COMPONENTS, COMPUTES THE WEIGHTED DENSITIES BASED ON THE MULTIVARIATE NORMAL DISTRIBUTION, AND NORMALIZES THEM TO OBTAIN THE RESPONSIBILITY MATRIX.
    def __ESTIMATE_RESPONSIBILITIES__(X, WEIGHTS, MEANS, COVARIANCES):
        """THE `__ESTIMATE_RESPONSIBILITIES__` FUNCTION IS A HELPER FUNCTION WITHIN THE `GAUSSIAN_MIXTURES` FUNCTION. ITS PURPOSE IS TO COMPUTE THE RESPONSIBILITIES, WHICH REPRESENT THE PROBABILITIES THAT EACH DATA SAMPLE BELONGS TO EACH GAUSSIAN COMPONENT.
            - INPUTS:
                - `X`: THE INPUT DATA REPRESENTED AS A NUMPY ARRAY, WHERE EACH ROW CORRESPONDS TO A DATA SAMPLE AND EACH COLUMN REPRESENTS A FEATURE.
                - `WEIGHTS`: THE WEIGHTS OF THE GAUSSIAN COMPONENTS.
                - `MEANS`: THE MEANS OF THE GAUSSIAN COMPONENTS.
                - `COVARIANCES`: THE COVARIANCE MATRICES OF THE GAUSSIAN COMPONENTS.
            - STEPS:
                1. INITIALIZE VARIABLES:
                    - `N_SAMPLES` STORES THE NUMBER OF DATA SAMPLES (ROWS) IN THE INPUT DATA `X`.
                    - `K` STORES THE NUMBER OF GAUSSIAN COMPONENTS.
                    - INITIALIZE `WEIGHTED_DENSITIES` AS A MATRIX OF ZEROS WITH SHAPE `(N_SAMPLES, K)` TO STORE THE WEIGHTED DENSITIES FOR EACH SAMPLE AND COMPONENT.
                2. COMPUTE WEIGHTED DENSITIES:
                    - FOR EACH COMPONENT `I` FROM 0 TO `K-1`, DO THE FOLLOWING:
                    - COMPUTE THE MULTIVARIATE NORMAL DENSITY FOR EACH DATA SAMPLE `X` USING THE `__MULTIVARIATE_NORMAL__` FUNCTION. THIS IS DONE BY PASSING THE DATA SAMPLES `X`, THE MEAN `MEANS[I]`, AND THE COVARIANCE MATRIX `COVARIANCES[I]`.
                    - MULTIPLY THE COMPUTED DENSITY BY THE WEIGHT OF THE COMPONENT `WEIGHTS[I]`.
                    - STORE THE RESULTING WEIGHTED DENSITY IN THE `WEIGHTED_DENSITIES` MATRIX FOR THE CORRESPONDING SAMPLE AND COMPONENT.
                3. COMPUTE RESPONSIBILITY MATRIX:
                    - COMPUTE THE SUM OF THE WEIGHTED DENSITIES FOR EACH DATA SAMPLE ACROSS ALL COMPONENTS USING `NP.SUM(WEIGHTED_DENSITIES, AXIS=1, KEEPDIMS=TRUE)`. THIS PROVIDES A NORMALIZATION FACTOR FOR EACH SAMPLE.
                    - DIVIDE EACH ELEMENT OF `WEIGHTED_DENSITIES` BY ITS CORRESPONDING NORMALIZATION FACTOR. THIS YIELDS THE RESPONSIBILITY MATRIX, WHERE EACH ELEMENT REPRESENTS THE PROBABILITY THAT A DATA SAMPLE BELONGS TO A SPECIFIC COMPONENT.
            - OUTPUT: RETURN THE RESPONSIBILITY MATRIX, WHICH HAS THE SHAPE `(N_SAMPLES, K)`.
        IN SUMMARY, THE `__ESTIMATE_RESPONSIBILITIES__` FUNCTION COMPUTES THE RESPONSIBILITIES BY CALCULATING THE PROBABILITIES THAT EACH DATA SAMPLE BELONGS TO EACH GAUSSIAN COMPONENT. IT DOES THIS BY COMPUTING THE WEIGHTED DENSITIES FOR EACH SAMPLE AND COMPONENT AND NORMALIZING THEM TO OBTAIN THE RESPONSIBILITY MATRIX. THIS MATRIX IS THEN USED IN SUBSEQUENT STEPS OF THE GMM ALGORITHM TO UPDATE THE PARAMETERS AND ASSIGN LABELS TO THE DATA SAMPLES."""
        N_SAMPLES = X.shape[0]
        K = WEIGHTS.shape[0]
        WEIGHTED_DENSITIES = np.zeros((N_SAMPLES, K))
        for i in range(K):
            WEIGHTED_DENSITIES[:, i] = WEIGHTS[i] * __MULTIVARIATE_NORMAL__(X, MEANS[i], COVARIANCES[i])
        RESPONSIBILITY_MATRIX = WEIGHTED_DENSITIES / np.sum(WEIGHTED_DENSITIES, axis=1, keepdims=True)
        return RESPONSIBILITY_MATRIX

    # THE `__ESTIMATE_PARAMETERS__` FUNCTION IS ANOTHER HELPER FUNCTION WITHIN THE `GAUSSIAN_MIXTURES` FUNCTION. ITS PURPOSE IS TO ESTIMATE THE PARAMETERS OF THE GAUSSIAN COMPONENTS BASED ON THE RESPONSIBILITY MATRIX.
    #     1. INPUTS:
    #         - `X`: THE INPUT DATA REPRESENTED AS A NUMPY ARRAY.
    #         - `RESPONSIBILITY_MATRIX`: THE RESPONSIBILITY MATRIX REPRESENTING THE PROBABILITIES THAT EACH DATA SAMPLE BELONGS TO EACH GAUSSIAN COMPONENT.
    #     2. THE FUNCTION BEGINS BY EXTRACTING THE NUMBER OF SAMPLES (`N_SAMPLES`) AND THE NUMBER OF FEATURES (`N_FEATURES`) FROM THE SHAPE OF THE INPUT DATA `X` AND THE RESPONSIBILITY MATRIX.
    #     3. IT CREATES AN EMPTY ARRAY CALLED `RESPONSIBILITY_MATRIX_SUM` WITH THE SHAPE `(K,)` TO STORE THE SUM OF RESPONSIBILITIES FOR EACH GAUSSIAN COMPONENT. `K` REPRESENTS THE NUMBER OF GAUSSIAN COMPONENTS.
    #     4. THE FUNCTION THEN COMPUTES THE SUM OF RESPONSIBILITIES ACROSS ALL DATA SAMPLES FOR EACH GAUSSIAN COMPONENT. THIS IS DONE BY SUMMING THE ELEMENTS ALONG THE ROWS (AXIS 0) OF THE RESPONSIBILITY MATRIX AND STORING THE RESULT IN THE `RESPONSIBILITY_MATRIX_SUM` ARRAY.
    #     5. IT COMPUTES THE UPDATED WEIGHTS (`WEIGHTS`) OF THE GAUSSIAN COMPONENTS BY DIVIDING THE SUM OF RESPONSIBILITIES FOR EACH COMPONENT BY THE TOTAL NUMBER OF SAMPLES (`N_SAMPLES`).
    #         - THIS STEP NORMALIZES THE SUM OF RESPONSIBILITIES, ENSURING THAT THE WEIGHTS SUM UP TO 1.
    #     6. NEXT, IT COMPUTES THE UPDATED MEANS (`MEANS`) OF THE GAUSSIAN COMPONENTS BY CALCULATING THE WEIGHTED AVERAGE OF THE DATA SAMPLES, WHERE THE WEIGHTS ARE DETERMINED BY THE RESPONSIBILITY MATRIX.
    #         - IT TRANSPOSES THE RESPONSIBILITY MATRIX AND PERFORMS A DOT PRODUCT WITH THE INPUT DATA `X`, WHICH GIVES A WEIGHTED SUM OF THE DATA SAMPLES FOR EACH COMPONENT.
    #         - THE RESULTING SUM IS DIVIDED ELEMENT-WISE BY THE `RESPONSIBILITY_MATRIX_SUM` ARRAY TO OBTAIN THE WEIGHTED AVERAGE FOR EACH COMPONENT.
    #         - THE RESULT IS STORED IN THE `MEANS` ARRAY.
    #     7. FOR EACH GAUSSIAN COMPONENT, THE FUNCTION COMPUTES THE UPDATED COVARIANCE MATRICES (`COVARIANCES`) BY TAKING INTO ACCOUNT THE WEIGHTED DIFFERENCES BETWEEN THE DATA SAMPLES AND THE MEANS.
    #         - IT ITERATES OVER EACH COMPONENT USING A `FOR` LOOP.
    #         - FOR EACH COMPONENT `I`, IT COMPUTES THE DIFFERENCE BETWEEN THE INPUT DATA `X` AND THE MEAN OF THE COMPONENT (`MEANS[I]`).
    #         - IT THEN MULTIPLIES THE RESPONSIBILITY VALUES FOR COMPONENT `I` IN THE RESPONSIBILITY MATRIX (`RESPONSIBILITY_MATRIX[:, I]`) WITH THE CORRESPONDING DIFFERENCES TO OBTAIN WEIGHTED DIFFERENCES.
    #         - THE WEIGHTED DIFFERENCES ARE USED TO COMPUTE THE COVARIANCE MATRIX BY TAKING THE DOT PRODUCT OF THE TRANSPOSED WEIGHTED DIFFERENCES AND THE ORIGINAL DIFFERENCES.
    #         - THE RESULTING COVARIANCE MATRIX IS DIVIDED ELEMENT-WISE BY THE `RESPONSIBILITY_MATRIX_SUM[I]` VALUE TO OBTAIN THE WEIGHTED COVARIANCE MATRIX FOR COMPONENT `I`.
    #         - THE RESULTING COVARIANCE MATRIX IS ADDED TO THE `COVARIANCES` LIST.
    #     8. FINALLY, THE FUNCTION CONVERTS THE `COVARIANCES` LIST TO A NUMPY ARRAY AND RETURNS THE UPDATED WEIGHTS (`WEIGHTS`), MEANS (`MEANS`), AND COVARIANCES (`COVARIANCES`).
    # IN SUMMARY, THE `__ESTIMATE_PARAMETERS__` FUNCTION ESTIMATES THE PARAMETERS (WEIGHTS, MEANS, AND COVARIANCES) OF THE GAUSSIAN COMPONENTS BASED ON THE RESPONSIBILITY MATRIX. IT COMPUTES THE UPDATED WEIGHTS BY NORMALIZING THE SUM OF RESPONSIBILITIES, CALCULATES THE WEIGHTED MEANS USING A WEIGHTED AVERAGE OF THE DATA SAMPLES, AND DETERMINES THE WEIGHTED COVARIANCE MATRICES BY CONSIDERING THE WEIGHTED DIFFERENCES BETWEEN THE DATA SAMPLES AND THE MEANS FOR EACH COMPONENT.
    def __ESTIMATE_PARAMETERS__(X, RESPONSIBILITY_MATRIX):
        """THE `__ESTIMATE_PARAMETERS__` FUNCTION IS A HELPER FUNCTION WITHIN THE `GAUSSIAN_MIXTURES` ALGORITHM.
            - INPUTS:
                - `X`: THE INPUT DATA REPRESENTED AS A NUMPY ARRAY.
                - `RESPONSIBILITY_MATRIX`: THE RESPONSIBILITY MATRIX REPRESENTING THE PROBABILITIES THAT EACH DATA SAMPLE BELONGS TO EACH GAUSSIAN COMPONENT.
            - STEPS:
                1. EXTRACT THE NUMBER OF SAMPLES AND FEATURES FROM THE INPUT DATA.
                2. COMPUTE THE SUM OF RESPONSIBILITIES ACROSS ALL DATA SAMPLES FOR EACH GAUSSIAN COMPONENT.
                3. UPDATE THE WEIGHTS BY DIVIDING THE SUM OF RESPONSIBILITIES BY THE TOTAL NUMBER OF SAMPLES.
                4. CALCULATE THE WEIGHTED MEANS BY TAKING THE WEIGHTED AVERAGE OF THE DATA SAMPLES BASED ON THE RESPONSIBILITY MATRIX.
                5. COMPUTE THE WEIGHTED DIFFERENCES BETWEEN THE DATA SAMPLES AND MEANS FOR EACH COMPONENT.
                6. CALCULATE THE WEIGHTED COVARIANCE MATRICES BY TAKING THE DOT PRODUCT OF THE TRANSPOSED WEIGHTED DIFFERENCES AND THE ORIGINAL DIFFERENCES.
                7. NORMALIZE THE COVARIANCE MATRICES BY DIVIDING THEM ELEMENT-WISE BY THE RESPECTIVE SUM OF RESPONSIBILITIES.
                8. RETURN THE UPDATED WEIGHTS, MEANS, AND COVARIANCES.
            - SUMMARY: THE `__ESTIMATE_PARAMETERS__` FUNCTION UPDATES THE PARAMETERS (WEIGHTS, MEANS, AND COVARIANCES) OF THE GAUSSIAN COMPONENTS BASED ON THE RESPONSIBILITY MATRIX. IT COMPUTES THE WEIGHTS BY NORMALIZING THE SUM OF RESPONSIBILITIES, CALCULATES THE WEIGHTED MEANS USING A WEIGHTED AVERAGE OF THE DATA SAMPLES, AND DETERMINES THE WEIGHTED COVARIANCE MATRICES BY CONSIDERING THE WEIGHTED DIFFERENCES BETWEEN THE DATA SAMPLES AND THE MEANS FOR EACH COMPONENT."""
        N_SAMPLES = X.shape[0]
        K = RESPONSIBILITY_MATRIX.shape[1]
        RESPONSIBILITY_MATRIX_SUM = np.sum(RESPONSIBILITY_MATRIX, axis=0)
        WEIGHTS = RESPONSIBILITY_MATRIX_SUM / N_SAMPLES
        MEANS = np.dot(RESPONSIBILITY_MATRIX.T, X) / RESPONSIBILITY_MATRIX_SUM[:, np.newaxis]
        COVARIANCES = []
        for i in range(K):
            DIFFERENCE = X - MEANS[i]
            WEIGHTED_DIFFERENCE = RESPONSIBILITY_MATRIX[:, i][:, np.newaxis] * DIFFERENCE
            COVARIANCES.append(np.dot(WEIGHTED_DIFFERENCE.T, DIFFERENCE) / RESPONSIBILITY_MATRIX_SUM[i])
        COVARIANCES = np.array(COVARIANCES)
        return WEIGHTS, MEANS, COVARIANCES

    # THE `__MULTIVARIATE_NORMAL__` FUNCTION IS A HELPER FUNCTION WITHIN THE `GAUSSIAN_MIXTURES` ALGORITHM. ITS PURPOSE IS TO COMPUTE THE MULTIVARIATE NORMAL DISTRIBUTION FOR A GIVEN DATA SAMPLE, MEAN, AND COVARIANCE MATRIX.
    #     1. INPUTS:
    #         - `X`: THE INPUT DATA, REPRESENTED AS A NUMPY ARRAY.
    #         - `MEAN`: THE MEAN VECTOR OF THE MULTIVARIATE NORMAL DISTRIBUTION.
    #         - `COVARIANCE_MATRIX`: THE COVARIANCE MATRIX OF THE MULTIVARIATE NORMAL DISTRIBUTION.
    #     2. THE FUNCTION BEGINS BY EXTRACTING THE NUMBER OF FEATURES (`K`) FROM THE SHAPE OF THE INPUT DATA `X`.
    #     3. IT COMPUTES THE DETERMINANT OF THE COVARIANCE MATRIX (`COVARIANCE_MATRIX`) USING `NP.LINALG.DET`.
    #     4. NEXT, THE FUNCTION CALCULATES THE NORMALIZATION CONSTANT OF THE MULTIVARIATE NORMAL DISTRIBUTION.
    #         - IT USES THE FORMULA `1.0 / ((2 * NP.PI) ** (K / 2) * NP.SQRT(DETERMINANT))`.
    #         - THIS CONSTANT ENSURES THAT THE PROBABILITY DENSITY FUNCTION IS PROPERLY SCALED.
    #     5. THE FUNCTION COMPUTES THE INVERSE OF THE COVARIANCE MATRIX (`COVARIANCE_MATRIX`) USING `NP.LINALG.INV`. THIS IS NEEDED TO CALCULATE THE MAHALANOBIS DISTANCE LATER.
    #     6. IT CALCULATES THE EXPONENT OF THE MULTIVARIATE NORMAL DISTRIBUTION.
    #         - IT SUBTRACTS THE MEAN VECTOR (`MEAN`) FROM EACH DATA SAMPLE (`X`) AND OBTAINS THE DIFFERENCE.
    #         - IT PERFORMS MATRIX MULTIPLICATION BETWEEN THE DIFFERENCE AND THE INVERSE OF THE COVARIANCE MATRIX.
    #         - THE RESULTING MATRIX IS ELEMENT-WISE MULTIPLIED WITH THE DIFFERENCE, AND THEN SUMMED ACROSS THE COLUMNS.
    #         - FINALLY, THE RESULT IS MULTIPLIED BY -0.5.
    #     7. THE FUNCTION COMPUTES THE FINAL PROBABILITY DENSITY VALUE OF THE MULTIVARIATE NORMAL DISTRIBUTION.
    #         - IT MULTIPLIES THE NORMALIZATION CONSTANT BY `NP.EXP(EXPONENT)`.
    #         - THIS STEP COMBINES THE NORMALIZATION CONSTANT WITH THE EXPONENTIAL TERM TO YIELD THE PROBABILITY DENSITY FOR EACH DATA SAMPLE.
    #     8. THE FUNCTION RETURNS THE COMPUTED PROBABILITY DENSITY VALUES.
    # IN SUMMARY, THE `__MULTIVARIATE_NORMAL__` FUNCTION CALCULATES THE MULTIVARIATE NORMAL DISTRIBUTION FOR A GIVEN DATA SAMPLE, MEAN, AND COVARIANCE MATRIX. IT COMPUTES THE NORMALIZATION CONSTANT, CALCULATES THE EXPONENT BASED ON THE MAHALANOBIS DISTANCE, AND COMBINES IT WITH THE NORMALIZATION CONSTANT TO OBTAIN THE PROBABILITY DENSITY VALUE FOR EACH DATA SAMPLE."""
    def __MULTIVARIATE_NORMAL__(X, MEAN, COVARIANCE_MATRIX):
        """THE `__MULTIVARIATE_NORMAL__` FUNCTION IS A HELPER FUNCTION WITHIN THE `GAUSSIAN_MIXTURES` ALGORITHM.
            - INPUTS:
                - `X`: THE INPUT DATA REPRESENTED AS A NUMPY ARRAY.
                - `MEAN`: THE MEAN VECTOR OF THE MULTIVARIATE NORMAL DISTRIBUTION.
                - `COVARIANCE_MATRIX`: THE COVARIANCE MATRIX OF THE MULTIVARIATE NORMAL DISTRIBUTION.
            - STEPS:
                1. EXTRACT THE NUMBER OF FEATURES FROM THE INPUT DATA.
                2. CALCULATE THE DETERMINANT OF THE COVARIANCE MATRIX.
                3. COMPUTE THE NORMALIZATION CONSTANT OF THE MULTIVARIATE NORMAL DISTRIBUTION.
                4. CALCULATE THE EXPONENT OF THE MULTIVARIATE NORMAL DISTRIBUTION BASED ON THE MAHALANOBIS DISTANCE.
                5. MULTIPLY THE NORMALIZATION CONSTANT BY THE EXPONENTIAL TERM TO OBTAIN THE PROBABILITY DENSITY VALUE FOR EACH DATA SAMPLE.
            - SUMMARY: THE `__MULTIVARIATE_NORMAL__` FUNCTION CALCULATES THE MULTIVARIATE NORMAL DISTRIBUTION FOR A GIVEN DATA SAMPLE, MEAN, AND COVARIANCE MATRIX. IT COMPUTES THE NORMALIZATION CONSTANT, CALCULATES THE EXPONENT BASED ON THE MAHALANOBIS DISTANCE, AND COMBINES IT WITH THE NORMALIZATION CONSTANT TO OBTAIN THE PROBABILITY DENSITY VALUE FOR EACH DATA SAMPLE."""
        K = X.shape[1]
        DETERMINANT = np.linalg.det(COVARIANCE_MATRIX)
        NORMALIZATION_CONSTANT = 1.0 / ((2 * np.pi) ** (K / 2) * np.sqrt(DETERMINANT))
        INVERSE_OF_COVARIANCE_MATRIX = np.linalg.inv(COVARIANCE_MATRIX)
        EXPONENT = -0.5 * np.sum(np.dot((X - MEAN), INVERSE_OF_COVARIANCE_MATRIX) * (X - MEAN), axis=1)
        return NORMALIZATION_CONSTANT * np.exp(EXPONENT)

    # THE `__LOG_LIKELIHOOD__` FUNCTION IS A HELPER FUNCTION WITHIN THE `GAUSSIAN_MIXTURES` ALGORITHM. ITS PURPOSE IS TO COMPUTE THE LOG-LIKELIHOOD OF THE GAUSSIAN MIXTURE MODEL (GMM) GIVEN THE CURRENT PARAMETERS.
    #     1. INPUTS:
    #         - `X`: THE INPUT DATA, REPRESENTED AS A NUMPY ARRAY.
    #         - `WEIGHTS`: THE WEIGHTS OF THE GAUSSIAN COMPONENTS.
    #         - `MEANS`: THE MEANS OF THE GAUSSIAN COMPONENTS.
    #         - `COVARIANCES`: THE COVARIANCE MATRICES OF THE GAUSSIAN COMPONENTS.
    #     2. THE FUNCTION BEGINS BY EXTRACTING THE NUMBER OF SAMPLES (`N_SAMPLES`) FROM THE SHAPE OF THE INPUT DATA `X`.
    #     3. IT CREATES AN EMPTY ARRAY CALLED `LOG_LIKELIHOODS` TO STORE THE LOG-LIKELIHOOD VALUES FOR EACH DATA SAMPLE.
    #     4. THE FUNCTION ITERATES OVER EACH GAUSSIAN COMPONENT USING A `FOR` LOOP.
    #         - FOR EACH COMPONENT `I`, IT COMPUTES THE MULTIVARIATE NORMAL DISTRIBUTION FOR THE INPUT DATA `X`, MEAN OF THE COMPONENT (`MEANS[I]`), AND COVARIANCE MATRIX OF THE COMPONENT (`COVARIANCES[I]`).
    #         - IT MULTIPLIES THE RESULTING PROBABILITY DENSITY VALUES BY THE WEIGHT OF THE COMPONENT (`WEIGHTS[I]`).
    #         - THE RESULTING ARRAY OF WEIGHTED PROBABILITY DENSITY VALUES IS ADDED TO THE `LOG_LIKELIHOODS` ARRAY.
    #     5. NEXT, THE FUNCTION CALCULATES THE LOG-LIKELIHOOD BY TAKING THE LOGARITHM OF THE SUM OF THE VALUES IN THE `LOG_LIKELIHOODS` ARRAY.
    #         - THE SUM IS COMPUTED USING `NP.SUM`.
    #         - TAKING THE LOGARITHM OF THE SUM IS NECESSARY TO WORK IN THE LOG SPACE AND AVOID NUMERICAL UNDERFLOW.
    #     6. FINALLY, THE FUNCTION RETURNS THE COMPUTED LOG-LIKELIHOOD.
    # IN SUMMARY, THE `__LOG_LIKELIHOOD__` FUNCTION COMPUTES THE LOG-LIKELIHOOD OF THE GMM GIVEN THE CURRENT PARAMETERS. IT ITERATES OVER THE GAUSSIAN COMPONENTS, COMPUTES THE PROBABILITY DENSITY VALUES BASED ON THE MULTIVARIATE NORMAL DISTRIBUTION, WEIGHTS THEM BY THE COMPONENT WEIGHTS, AND CALCULATES THE LOG-LIKELIHOOD BY TAKING THE LOGARITHM OF THE SUM OF THESE WEIGHTED PROBABILITY DENSITY VALUES.
    def __LOG_LIKELIHOOD__(X, WEIGHTS, MEANS, COVARIANCES):
        """THE `__LOG_LIKELIHOOD__` FUNCTION IS A HELPER FUNCTION WITHIN THE `GAUSSIAN_MIXTURES` ALGORITHM.
            - INPUTS:
                - `X`: THE INPUT DATA REPRESENTED AS A NUMPY ARRAY.
                - `WEIGHTS`: THE WEIGHTS OF THE GAUSSIAN COMPONENTS.
                - `MEANS`: THE MEANS OF THE GAUSSIAN COMPONENTS.
                - `COVARIANCES`: THE COVARIANCE MATRICES OF THE GAUSSIAN COMPONENTS.
            - STEPS:
                1. EXTRACT THE NUMBER OF SAMPLES FROM THE INPUT DATA.
                2. ITERATE OVER EACH GAUSSIAN COMPONENT.
                    - COMPUTE THE PROBABILITY DENSITY VALUES FOR THE DATA SAMPLES USING THE MULTIVARIATE NORMAL DISTRIBUTION.
                    - WEIGHT THE PROBABILITY DENSITY VALUES BY THE COMPONENT WEIGHTS.
                    - STORE THE WEIGHTED PROBABILITY DENSITY VALUES IN AN ARRAY.
                3. CALCULATE THE LOG-LIKELIHOOD BY TAKING THE LOGARITHM OF THE SUM OF THE WEIGHTED PROBABILITY DENSITY VALUES.
            - SUMMARY: THE `__LOG_LIKELIHOOD__` FUNCTION COMPUTES THE LOG-LIKELIHOOD OF THE GMM BY ITERATING OVER THE GAUSSIAN COMPONENTS, COMPUTING THE PROBABILITY DENSITY VALUES, WEIGHTING THEM BY THE COMPONENT WEIGHTS, AND CALCULATING THE LOG-LIKELIHOOD BASED ON THE SUM OF THESE WEIGHTED PROBABILITY DENSITY VALUES."""
        LOG_LIKELIHOODS = np.log(np.sum([WEIGHTS[i] * __MULTIVARIATE_NORMAL__(X, MEANS[i], COVARIANCES[i]) for i in range(WEIGHTS.shape[0])], axis=0))
        return np.sum(LOG_LIKELIHOODS)

    N_SAMPLES, N_FEATURES = X.shape
    WEIGHTS = np.ones(K) / K
    MEANS = X[np.random.choice(N_SAMPLES, K, replace=False)]
    COVARIANCES = np.array([np.eye(N_FEATURES)] * K)
    PREVIOUS_LOG_LIKELIHOOD = 0.0
    for _ in range(MAX_ITERATIONS):
        RESPONSIBILITY_MATRIX = __ESTIMATE_RESPONSIBILITIES__(X, WEIGHTS, MEANS, COVARIANCES)
        WEIGHTS, MEANS, COVARIANCES = __ESTIMATE_PARAMETERS__(X, RESPONSIBILITY_MATRIX)
        LOG_LIKELIHOOD = __LOG_LIKELIHOOD__(X, WEIGHTS, MEANS, COVARIANCES)
        if np.abs(LOG_LIKELIHOOD - PREVIOUS_LOG_LIKELIHOOD) < TOLERANCE:
            break
        PREVIOUS_LOG_LIKELIHOOD = LOG_LIKELIHOOD
    RESPONSIBILITY_MATRIX = __ESTIMATE_RESPONSIBILITIES__(X, WEIGHTS, MEANS, COVARIANCES)
    LABELS = np.argmax(RESPONSIBILITY_MATRIX, axis=1)
    return LABELS