import numpy as np

# # THE PROVIDED CODE DEFINES A FUNCTION CALLED `K_MEANS_CLUSTERING` THAT IMPLEMENTS THE K-MEANS CLUSTERING ALGORITHM.
# #     1. `NP.RANDOM.SEED(42)`: THIS LINE SETS THE RANDOM SEED TO 42, WHICH ENSURES THAT THE RANDOM NUMBERS GENERATED BY NUMPY WILL BE THE SAME EVERY TIME YOU RUN THE CODE. IT HELPS WITH REPRODUCIBILITY OF THE RESULTS.
# #     2. `IDXS = NP.RANDOM.CHOICE(X.SHAPE[0], K, REPLACE=FALSE)`: HERE, `NP.RANDOM.CHOICE()` IS USED TO RANDOMLY SELECT K UNIQUE INDICES FROM THE RANGE [0, X.SHAPE[0]). THE `X.SHAPE[0]` RETURNS THE NUMBER OF DATA POINTS IN X. THESE INDICES REPRESENT THE INITIAL CENTROIDS FOR EACH CLUSTER.
# #     3. `CENTROIDS = X[IDXS]`: THE INITIAL CENTROIDS ARE SELECTED FROM THE DATA POINTS X USING THE INDICES OBTAINED IN THE PREVIOUS STEP. THIS CREATES AN INITIAL SET OF CENTROIDS FOR THE CLUSTERS.
# #     4. `PREV_CENTROIDS = NP.ZEROS_LIKE(CENTROIDS)`: THIS LINE CREATES AN ARRAY OF ZEROS WITH THE SAME SHAPE AS THE `CENTROIDS` ARRAY. THE `PREV_CENTROIDS` ARRAY WILL STORE THE PREVIOUS POSITIONS OF THE CENTROIDS.
# #     5. `LABELS = NP.ZEROS(X.SHAPE[0])`: AN ARRAY OF ZEROS WITH THE SAME LENGTH AS THE NUMBER OF DATA POINTS IN X IS CREATED. THE `LABELS` ARRAY WILL STORE THE CLUSTER ASSIGNMENTS FOR EACH DATA POINT.
# #     6. THE CODE ENTERS A LOOP THAT WILL RUN FOR A MAXIMUM OF `MAX_ITERATIONS` ITERATIONS.
# #     7. THE FIRST NESTED LOOP ITERATES OVER EACH DATA POINT IN X. FOR EACH DATA POINT, IT CALCULATES THE EUCLIDEAN DISTANCE BETWEEN THE DATA POINT AND EACH CENTROID USING `NP.LINALG.NORM(CENTROIDS - POINT, AXIS=1)`. THE RESULTING DISTANCES ARE STORED IN THE `DISTANCES` ARRAY.
# #     8. THE SECOND NESTED LOOP ITERATES OVER EACH CLUSTER. FOR EACH CLUSTER, IT SELECTS THE DATA POINTS THAT ARE ASSIGNED TO THAT CLUSTER USING `X[LABELS == CLUSTER]`. IF THERE ARE ANY DATA POINTS ASSIGNED TO THE CLUSTER, IT CALCULATES THE NEW CENTROID POSITION BY TAKING THE MEAN OF THE DATA POINTS ALONG EACH DIMENSION.
# #     9. AFTER UPDATING THE CENTROID POSITIONS, THE CODE CHECKS IF THE POSITIONS HAVE CONVERGED. IT USES THE `NP.ALLCLOSE()` FUNCTION TO COMPARE THE CURRENT CENTROID POSITIONS (`CENTROIDS`) WITH THE PREVIOUS POSITIONS (`PREV_CENTROIDS`). THE `RTOL=TOLERANCE` ARGUMENT SPECIFIES THE RELATIVE TOLERANCE FOR THE COMPARISON. IF THE DIFFERENCE BETWEEN ALL CORRESPONDING ELEMENTS OF THE TWO ARRAYS IS LESS THAN OR EQUAL TO `TOLERANCE`, THE CENTROIDS ARE CONSIDERED TO HAVE CONVERGED, AND THE LOOP IS TERMINATED.
# #     10. BEFORE THE LOOP RESTARTS, THE CURRENT CENTROID POSITIONS ARE COPIED TO `PREV_CENTROIDS` USING `PREV_CENTROIDS = CENTROIDS.COPY()`. THIS ENSURES THAT THE PREVIOUS POSITIONS ARE STORED FOR THE NEXT ITERATION.
# #     11. ONCE THE LOOP FINISHES OR THE CENTROIDS CONVERGE, THE FUNCTION RETURNS THE FINAL CENTROID POSITIONS (`CENTROIDS`) AND THE CLUSTER ASSIGNMENTS FOR EACH DATA POINT (`LABELS`).
# # IN SUMMARY, THE `K_MEANS_CLUSTERING` FUNCTION INITIALIZES CENTROIDS RANDOMLY, ASSIGNS DATA POINTS TO CLUSTERS BASED ON THE CLOSEST CENTROID, UPDATES THE CENTROID POSITIONS, AND REPEATS THESE STEPS UNTIL CONVERGENCE OR A MAXIMUM NUMBER OF ITERATIONS IS REACHED. THE FUNCTION RETURNS THE FINAL CENTROID POSITIONS AND THE CLUSTER ASSIGNMENTS.
# # THIS IMPLEMENTATION INITIALIZES THE CENTROIDS RANDOMLY, ASSIGNS EACH DATA POINT TO THE NEAREST CENTROID, AND THEN UPDATES THE CENTROIDS ITERATIVELY UNTIL CONVERGENCE OR UNTIL THE MAXIMUM NUMBER OF ITERATIONS IS REACHED. THE ALGORITHM WILL STOP WHEN THE CENTROIDS DO NOT CHANGE SIGNIFICANTLY, AS DETERMINED BY THE SPECIFIED TOLERANCE (TOL).
# # PLEASE NOTE THAT THE K-MEANS ALGORITHM CAN BE SENSITIVE TO THE INITIAL CENTROIDS' PLACEMENT, AND THE FINAL RESULT MAY VARY DEPENDING ON THE INITIAL RANDOM SEED. TO MITIGATE THIS ISSUE, YOU CAN RUN THE ALGORITHM MULTIPLE TIMES WITH DIFFERENT RANDOM SEEDS AND CHOOSE THE BEST RESULT BASED ON SOME CLUSTERING EVALUATION METRIC LIKE THE WITHIN-CLUSTER SUM OF SQUARES (WCSS) OR SILHOUETTE SCORE.
# def K_MEANS_CLUSTERING(X, K=3, MAX_ITERATIONS=100, TOLERANCE=1e-4):
#     """IMPLEMENTS THE K-MEANS CLUSTERING ALGORITHM. IT TAKES A DATASET `X` AND CLUSTERS IT INTO `K` DISTINCT CLUSTERS. THE MAIN STEPS OF THE K-MEANS ALGORITHM ARE AS FOLLOWS:
#         1. INITIALIZATION: RANDOMLY SELECT `K` DATA POINTS FROM THE DATASET AS INITIAL CENTROIDS.
#         2. ASSIGNMENT: ASSIGN EACH DATA POINT IN THE DATASET TO THE NEAREST CENTROID BASED ON THE EUCLIDEAN DISTANCE METRIC.
#         3. UPDATE: RECALCULATE THE CENTROIDS FOR EACH CLUSTER BY COMPUTING THE MEAN OF THE DATA POINTS IN EACH CLUSTER.
#         4. CONVERGENCE: REPEAT STEPS 2 AND 3 UNTIL EITHER THE MAXIMUM NUMBER OF ITERATIONS IS REACHED, OR THE CENTROIDS CONVERGE (I.E., THEY STOP CHANGING SIGNIFICANTLY).
#         THE ALGORITHM AIMS TO MINIMIZE THE VARIANCE WITHIN EACH CLUSTER AND MAXIMIZE THE SEPARATION BETWEEN DIFFERENT CLUSTERS, LEADING TO WELL-DEFINED AND COMPACT CLUSTERS.
#     THE FUNCTION'S PARAMETERS ARE AS FOLLOWS:
#         - `X`: THE INPUT DATASET TO BE CLUSTERED.
#         - `K`: THE NUMBER OF CLUSTERS (DEFAULT IS 3).
#         - `MAX_ITERATIONS`: THE MAXIMUM NUMBER OF ITERATIONS ALLOWED FOR THE ALGORITHM (DEFAULT IS 100).
#         - `TOLERANCE`: THE CONVERGENCE TOLERANCE TO DETERMINE IF THE CENTROIDS HAVE STABILIZED (DEFAULT IS 1E-4).
#     THE FUNCTION RETURNS THE FINAL `CENTROIDS`, WHICH ARE THE K CLUSTER CENTRES, AND `LABELS`, AN ARRAY INDICATING THE CLUSTER MEMBERSHIP OF EACH DATA POINT IN THE INPUT DATASET `X`."""
#     np.random.seed(42)  
#     IDXS = np.random.choice(X.shape[0], K, replace=False)
#     CENTROIDS = X[IDXS]
#     PREV_CENTROIDS = np.zeros_like(CENTROIDS)
#     LABELS = np.zeros(X.shape[0])
#     for _ in range(MAX_ITERATIONS):
#         for _IDX, POINT in enumerate(X):
#             DISTANCES = np.linalg.norm(CENTROIDS - POINT, axis=1)
#             LABELS[_IDX] = np.argmin(DISTANCES)
#         for CLUSTER in range(K):
#             CLUSTER_POINTS = X[LABELS == CLUSTER]
#             if len(CLUSTER_POINTS) > 0:
#                 CENTROIDS[CLUSTER] = np.mean(CLUSTER_POINTS, axis=0)
#         if np.allclose(CENTROIDS, PREV_CENTROIDS, rtol=TOLERANCE):
#             break
#         PREV_CENTROIDS = CENTROIDS.copy()
#     return CENTROIDS, LABELS

####################################################################################################

# THE `K_MEANS_CLUSTERING` FUNCTION IMPLEMENTS THE K-MEANS CLUSTERING ALGORITHM. GIVEN A SET OF DATA POINTS `X`, IT AIMS TO PARTITION THE DATA INTO `K` CLUSTERS BY ITERATIVELY ADJUSTING THE POSITIONS OF CENTROIDS.
#     1. THE `K_MEANS_CLUSTERING` FUNCTION TAKES THE INPUT DATA `X`, THE NUMBER OF CLUSTERS `K`, AND THE MAXIMUM NUMBER OF ITERATIONS `MAX_ITERATIONS` AS PARAMETERS.
#     2. INSIDE THE `K_MEANS_CLUSTERING` FUNCTION, THERE ARE SEVERAL HELPER FUNCTIONS DEFINED:
#         A. `__CREATE_CLUSTERS__` FUNCTION TAKES THE INPUT DATA `X` AND THE CURRENT CENTROIDS `CENTROIDS`. IT ASSIGNS EACH SAMPLE TO THE CLOSEST CENTROID AND RETURNS A LIST OF CLUSTERS, WHERE EACH CLUSTER IS A LIST OF INDICES OF THE SAMPLES BELONGING TO THAT CLUSTER.
#         B. `__CLOSEST_CENTROID__` FUNCTION CALCULATES THE EUCLIDEAN DISTANCE BETWEEN A SAMPLE `SAMPLE` AND EACH CENTROID IN `CENTROIDS`. IT RETURNS THE INDEX OF THE CLOSEST CENTROID.
#         C. `__GET_CENTROIDS__` FUNCTION TAKES THE LIST OF CLUSTERS AND CALCULATES THE MEAN OF EACH CLUSTER TO DETERMINE THE NEW CENTROID POSITIONS.
#         D. `__IS_CONVERGED__` FUNCTION CHECKS IF THE CENTROIDS HAVE CONVERGED BY COMPARING THE DISTANCES BETWEEN THE OLD CENTROIDS AND THE NEW CENTROIDS.
#         E. `__GET_CLUSTER_LABELS__` FUNCTION ASSIGNS CLUSTER LABELS TO EACH SAMPLE BASED ON THE INDICES IN THE LIST OF CLUSTERS.
#         F. `EUCLIDEAN_DISTANCE` FUNCTION CALCULATES THE EUCLIDEAN DISTANCE BETWEEN TWO SAMPLES `X_1` AND `X_2`.
#     3. THE CODE SETS THE RANDOM SEED TO 42 USING `NP.RANDOM.SEED(42)` FOR REPRODUCIBILITY.
#     4. THE NUMBER OF SAMPLES AND FEATURES IS EXTRACTED FROM THE SHAPE OF `X` USING `N_SAMPLES, N_FEATURES = X.SHAPE`.
#     5. INITIAL CENTROIDS ARE RANDOMLY SELECTED FROM THE SAMPLES WITHOUT REPLACEMENT USING `X[NP.RANDOM.CHOICE(N_SAMPLES, K, REPLACE=FALSE)]`.
#     6. THE CODE INITIALIZES AN EMPTY LIST OF CLUSTERS `CLUSTERS`.
#     7. THE MAIN LOOP RUNS FOR A MAXIMUM OF `MAX_ITERATIONS`.
#     8. IN EACH ITERATION, THE CODE CREATES NEW CLUSTERS BY CALLING `__CREATE_CLUSTERS__` WITH THE CURRENT DATA POINTS `X` AND CENTROIDS `CENTROIDS`.
#     9. THE NEW CENTROID POSITIONS ARE OBTAINED BY CALLING `__GET_CENTROIDS__` WITH THE NEW CLUSTERS.
#     10. THE CODE CHECKS IF THE CENTROIDS HAVE CONVERGED BY CALLING `__IS_CONVERGED__` WITH THE OLD AND NEW CENTROID POSITIONS. IF THEY HAVE CONVERGED, THE LOOP IS TERMINATED.
#     11. IF THE CENTROIDS HAVE NOT CONVERGED, THE NEW CLUSTERS BECOME THE CURRENT CLUSTERS, AND THE NEW CENTROID POSITIONS BECOME THE CURRENT CENTROIDS FOR THE NEXT ITERATION.
#     12. FINALLY, THE CLUSTER LABELS ARE OBTAINED BY CALLING `__GET_CLUSTER_LABELS__` WITH THE FINAL CLUSTERS.
#     13. THE FUNCTION RETURNS THE CLUSTER LABELS.
# IN SUMMARY, THIS CODE IMPLEMENTS THE K-MEANS CLUSTERING ALGORITHM BY ITERATIVELY ASSIGNING SAMPLES TO CLUSTERS, UPDATING CENTROID POSITIONS, AND CHECKING FOR CONVERGENCE. THE PROCESS CONTINUES UNTIL CONVERGENCE, OR THE MAXIMUM NUMBER OF ITERATIONS IS REACHED. THE FUNCTION RETURNS THE CLUSTER LABELS FOR EACH SAMPLE IN THE INPUT DATA.
def K_MEANS_CLUSTERING(X, K=3, MAX_ITERATIONS=100):
    """THE `K_MEANS_CLUSTERING` FUNCTION IMPLEMENTS THE K-MEANS CLUSTERING ALGORITHM. GIVEN A SET OF DATA POINTS `X`, IT AIMS TO PARTITION THE DATA INTO `K` CLUSTERS BY ITERATIVELY ADJUSTING THE POSITIONS OF CENTROIDS. HERE'S A BRIEF DESCRIPTION OF THE FUNCTION:
        1. RANDOMLY INITIALIZE `K` CENTROIDS FROM THE DATA POINTS.
        2. CREATE EMPTY CLUSTERS TO STORE THE INDICES OF SAMPLES BELONGING TO EACH CLUSTER.
        3. ITERATE UNTIL CONVERGENCE OR REACHING THE MAXIMUM NUMBER OF ITERATIONS:
            - ASSIGN EACH SAMPLE TO THE CLOSEST CENTROID, FORMING NEW CLUSTERS.
            - UPDATE THE CENTROID POSITIONS BY CALCULATING THE MEAN OF EACH CLUSTER.
            - CHECK FOR CONVERGENCE BY COMPARING THE DISTANCES BETWEEN OLD AND NEW CENTROIDS.
            - IF CONVERGED, EXIT THE LOOP.
            - OTHERWISE, UPDATE THE CURRENT CLUSTERS AND CENTROIDS FOR THE NEXT ITERATION.
        4. ASSIGN CLUSTER LABELS TO EACH SAMPLE BASED ON THE FINAL CLUSTERS.
        5. RETURN THE CLUSTER LABELS.
    THE K-MEANS ALGORITHM AIMS TO MINIMIZE THE WITHIN-CLUSTER SUM OF SQUARED DISTANCES, EFFECTIVELY GROUPING SIMILAR DATA POINTS TOGETHER. IT ITERATIVELY REFINES THE CLUSTER ASSIGNMENTS UNTIL CONVERGENCE, ENSURING THAT THE CENTROIDS REPRESENT THE CENTRES OF THEIR RESPECTIVE CLUSTERS. THE RESULT IS A SET OF CLUSTER LABELS THAT INDICATE WHICH CLUSTER EACH DATA POINT BELONGS TO."""

    # THE `__CREATE_CLUSTERS__` FUNCTION IS A HELPER FUNCTION USED IN THE K-MEANS CLUSTERING ALGORITHM. ITS PURPOSE IS TO ASSIGN DATA POINTS TO CLUSTERS BASED ON THEIR PROXIMITY TO CENTROIDS.
    #     1. THE FUNCTION `__CREATE_CLUSTERS__` TAKES TWO ARGUMENTS: `X` REPRESENTS THE DATA POINTS, AND `CENTROIDS` CONTAINS THE POSITIONS OF THE CENTROIDS.
    #     2. IT INITIALIZES AN EMPTY LIST CALLED `CLUSTERS` USING A LIST COMPREHENSION. THE LENGTH OF `CLUSTERS` IS EQUAL TO THE NUMBER OF CENTROIDS, WHICH MEANS THERE WILL BE ONE CLUSTER FOR EACH CENTROID.
    #     3. IT ITERATES OVER EACH DATA POINT IN `X` USING THE `ENUMERATE` FUNCTION, WHICH PROVIDES BOTH THE INDEX (`IDX`) AND THE CORRESPONDING DATA POINT (`SAMPLE`).
    #     4. INSIDE THE LOOP, IT CALLS THE `__CLOSEST_CENTROID__` HELPER FUNCTION TO DETERMINE THE INDEX OF THE CLOSEST CENTROID TO THE CURRENT DATA POINT. THIS FUNCTION CALCULATES THE EUCLIDEAN DISTANCE BETWEEN THE DATA POINT AND EACH CENTROID AND RETURNS THE INDEX OF THE CENTROID WITH THE SMALLEST DISTANCE.
    #     5. IT APPENDS THE INDEX (`IDX`) OF THE CURRENT DATA POINT TO THE APPROPRIATE CLUSTER IN THE `CLUSTERS` LIST. THE INDEX OF THE CLOSEST CENTROID (`CLOSEST_CENTROID_IDX`) DETERMINES WHICH CLUSTER THE DATA POINT BELONGS TO.
    #     6. AFTER ITERATING OVER ALL THE DATA POINTS, IT RETURNS THE `CLUSTERS` LIST, WHERE EACH ELEMENT REPRESENTS A CLUSTER AND CONTAINS THE INDICES OF THE DATA POINTS ASSIGNED TO THAT CLUSTER.
    # IN SUMMARY, THE `__CREATE_CLUSTERS__` FUNCTION ASSIGNS EACH DATA POINT IN `X` TO THE NEAREST CENTROID IN `CENTROIDS` AND ORGANIZES THE DATA POINTS INTO CLUSTERS BASED ON THESE ASSIGNMENTS. THE RESULTING `CLUSTERS` LIST IS A LIST OF LISTS, WHERE EACH INNER LIST REPRESENTS A CLUSTER AND CONTAINS THE INDICES OF THE DATA POINTS ASSIGNED TO THAT CLUSTER. THIS FUNCTION IS A KEY STEP IN THE K-MEANS CLUSTERING ALGORITHM, AS IT DETERMINES THE INITIAL ASSIGNMENT OF DATA POINTS TO CLUSTERS AND IS USED TO UPDATE THE CENTROIDS IN EACH ITERATION.
    def __CREATE_CLUSTERS__(X, CENTROIDS):
        """THE `__CREATE_CLUSTERS__` FUNCTION IS A HELPER FUNCTION USED WITHIN THE `K_MEANS_CLUSTERING` FUNCTION TO ASSIGN DATA POINTS TO THEIR NEAREST CENTROIDS AND CREATE CLUSTERS BASED ON THESE ASSIGNMENTS. HERE'S AN EXPLANATION OF THE FUNCTION:
            1. IT TAKES TWO INPUTS: `X`, WHICH REPRESENTS THE DATA POINTS, AND `CENTROIDS`, WHICH CONTAINS THE POSITIONS OF THE CENTROIDS.
            2. IT INITIALIZES AN EMPTY LIST CALLED `CLUSTERS` TO STORE THE CLUSTERS. THE LENGTH OF `CLUSTERS` IS EQUAL TO THE NUMBER OF CENTROIDS.
            3. IT ITERATES OVER EACH DATA POINT IN `X` AND FINDS THE CLOSEST CENTROID USING THE `__CLOSEST_CENTROID__` HELPER FUNCTION.
            4. IT APPENDS THE INDEX OF THE CURRENT DATA POINT TO THE CORRESPONDING CLUSTER IN `CLUSTERS` BASED ON THE INDEX OF THE CLOSEST CENTROID.
            5. AFTER ITERATING OVER ALL DATA POINTS, IT RETURNS THE `CLUSTERS` LIST, WHERE EACH ELEMENT REPRESENTS A CLUSTER AND CONTAINS THE INDICES OF THE DATA POINTS ASSIGNED TO THAT CLUSTER.
        IN SUMMARY, THE `__CREATE_CLUSTERS__` FUNCTION ASSIGNS DATA POINTS TO THEIR NEAREST CENTROIDS AND ORGANIZES THEM INTO CLUSTERS BASED ON THESE ASSIGNMENTS. IT SERVES AS A CRUCIAL STEP IN THE K-MEANS ALGORITHM, ALLOWING THE ALGORITHM TO UPDATE THE CENTROID POSITIONS AND REFINE THE CLUSTERS IN SUBSEQUENT ITERATIONS."""
        CLUSTERS = [[] for _ in range(len(CENTROIDS))]
        for IDX, SAMPLE in enumerate(X):
            CLOSEST_CENTROID_IDX = __CLOSEST_CENTROID__(SAMPLE, CENTROIDS)
            CLUSTERS[CLOSEST_CENTROID_IDX].append(IDX)        
        return CLUSTERS

    # THE `__CLOSEST_CENTROID__` FUNCTION IS A HELPER FUNCTION USED IN THE K-MEANS CLUSTERING ALGORITHM. ITS PURPOSE IS TO FIND THE INDEX OF THE CLOSEST CENTROID TO A GIVEN DATA POINT. LET'S GO THROUGH ITS IMPLEMENTATION AND BEHAVIOR IN DETAIL:
    #     1. THE FUNCTION TAKES TWO ARGUMENTS: `SAMPLE`, REPRESENTING THE DATA POINT FOR WHICH WE WANT TO FIND THE CLOSEST CENTROID, AND `CENTROIDS`, WHICH IS AN ARRAY CONTAINING THE POSITIONS OF ALL THE CENTROIDS.
    #     2. IT INITIALIZES AN EMPTY LIST CALLED `DISTANCES`, WHICH WILL STORE THE EUCLIDEAN DISTANCES BETWEEN THE `SAMPLE` AND EACH CENTROID.
    #     3. THE FUNCTION THEN ITERATES OVER EACH CENTROID IN `CENTROIDS`. FOR EACH CENTROID, IT CALCULATES THE EUCLIDEAN DISTANCE TO THE `SAMPLE` USING THE `EUCLIDEAN_DISTANCE` HELPER FUNCTION.
    #     4. THE `EUCLIDEAN_DISTANCE` HELPER FUNCTION TAKES TWO DATA POINTS (IN THIS CASE, THE `SAMPLE` AND A CENTROID) AND COMPUTES THE EUCLIDEAN DISTANCE BETWEEN THEM. EUCLIDEAN DISTANCE IS A MEASURE OF THE STRAIGHT-LINE DISTANCE BETWEEN TWO POINTS IN A MULTI-DIMENSIONAL SPACE. IT IS COMPUTED AS THE SQUARE ROOT OF THE SUM OF THE SQUARED DIFFERENCES BETWEEN THE COORDINATES OF THE TWO POINTS.
    #     5. THE CALCULATED EUCLIDEAN DISTANCE FOR EACH CENTROID IS APPENDED TO THE `DISTANCES` LIST.
    #     6. AFTER CALCULATING THE DISTANCES TO ALL CENTROIDS, THE FUNCTION USES `NP.ARGMIN(DISTANCES)` TO FIND THE INDEX OF THE CENTROID WITH THE SMALLEST DISTANCE. THIS INDEX CORRESPONDS TO THE INDEX OF THE CLOSEST CENTROID IN THE `CENTROIDS` ARRAY.
    #     7. THE FUNCTION RETURNS THE INDEX OF THE CLOSEST CENTROID.
    # IN SUMMARY, THE `__CLOSEST_CENTROID__` FUNCTION COMPUTES THE EUCLIDEAN DISTANCES BETWEEN A GIVEN DATA POINT (`SAMPLE`) AND ALL CENTROIDS IN THE `CENTROIDS` ARRAY. IT THEN RETURNS THE INDEX OF THE CENTROID WITH THE SMALLEST DISTANCE, INDICATING WHICH CENTROID IS CLOSEST TO THE DATA POINT. THIS INFORMATION IS CRUCIAL IN THE K-MEANS ALGORITHM, AS IT DETERMINES THE CLUSTER ASSIGNMENT OF THE DATA POINT DURING THE CLUSTERING PROCESS.
    def __CLOSEST_CENTROID__(SAMPLE, CENTROIDS):
        """THE `__CLOSEST_CENTROID__` FUNCTION IS A HELPER FUNCTION USED IN THE K-MEANS CLUSTERING ALGORITHM. IT CALCULATES THE EUCLIDEAN DISTANCES BETWEEN A GIVEN DATA POINT AND ALL CENTROIDS AND RETURNS THE INDEX OF THE CENTROID WITH THE SMALLEST DISTANCE. THIS INDEX INDICATES WHICH CENTROID IS CLOSEST TO THE DATA POINT AND IS USED TO ASSIGN THE DATA POINT TO A CLUSTER DURING THE CLUSTERING PROCESS."""
        DISTANCES = [EUCLIDEAN_DISTANCE(SAMPLE, CENTROID) for CENTROID in CENTROIDS]
        CLOSEST_IDX = np.argmin(DISTANCES)
        return CLOSEST_IDX

    # THE `__GET_CENTROIDS__` FUNCTION IS A HELPER FUNCTION USED IN THE K-MEANS CLUSTERING ALGORITHM. IT TAKES A LIST OF CLUSTERS AS INPUT AND CALCULATES THE CENTROID FOR EACH CLUSTER.
    #     1. IT INITIALIZES AN ARRAY `CENTROIDS` OF ZEROS WITH DIMENSIONS `(LEN(CLUSTERS), LEN(CLUSTERS[0][0]))`. THIS ARRAY WILL STORE THE CENTROIDS FOR EACH CLUSTER.
    #         - `LEN(CLUSTERS)` REPRESENTS THE NUMBER OF CLUSTERS, AND `LEN(CLUSTERS[0][0])` REPRESENTS THE NUMBER OF FEATURES IN EACH DATA POINT.
    #     2. IT ITERATES OVER EACH CLUSTER IN THE LIST OF CLUSTERS USING THE `ENUMERATE` FUNCTION.
    #         - `IDX` IS THE INDEX OF THE CURRENT CLUSTER BEING PROCESSED, AND `CLUSTER` IS THE LIST OF DATA POINT INDICES BELONGING TO THAT CLUSTER.
    #     3. FOR EACH CLUSTER, IT CALCULATES THE MEAN OF THE DATA POINTS IN THAT CLUSTER ALONG THE FIRST AXIS (AXIS 0).
    #        - `NP.MEAN(CLUSTER, AXIS=0)` CALCULATES THE MEAN VALUE FOR EACH FEATURE ACROSS THE DATA POINTS IN THE CLUSTER.
    #     4. IT ASSIGNS THE CALCULATED MEAN AS THE CENTROID FOR THE CURRENT CLUSTER BY UPDATING THE CORRESPONDING ROW IN THE `CENTROIDS` ARRAY.
    #        - `CENTROIDS[IDX] = CLUSTER_MEAN` ASSIGNS THE CALCULATED MEAN TO THE `IDX`-TH ROW OF THE `CENTROIDS` ARRAY.
    #     5. AFTER ITERATING OVER ALL CLUSTERS, IT RETURNS THE `CENTROIDS` ARRAY CONTAINING THE CENTROIDS FOR EACH CLUSTER.
    # IN SUMMARY, THE `__GET_CENTROIDS__` FUNCTION CALCULATES THE CENTROID FOR EACH CLUSTER BY TAKING THE MEAN OF THE DATA POINTS IN THE CLUSTER ALONG THE FIRST AXIS AND RETURNS AN ARRAY OF CENTROIDS. THESE CENTROIDS REPRESENT THE CENTER POINTS OF THE CLUSTERS AND ARE USED IN THE K-MEANS ALGORITHM FOR ASSIGNING DATA POINTS TO THEIR NEAREST CLUSTERS.
    def __GET_CENTROIDS__(CLUSTERS):
        """THE `__GET_CENTROIDS__` FUNCTION IS A HELPER FUNCTION USED IN THE K-MEANS CLUSTERING ALGORITHM. IT TAKES A LIST OF CLUSTERS AS INPUT AND CALCULATES THE CENTROID FOR EACH CLUSTER. THE CENTROID IS THE MEAN VALUE OF THE DATA POINTS IN THE CLUSTER.
            1. INITIALIZE AN ARRAY `CENTROIDS` OF ZEROS WITH DIMENSIONS `(LEN(CLUSTERS), LEN(CLUSTERS[0][0]))`, WHERE `LEN(CLUSTERS)` REPRESENTS THE NUMBER OF CLUSTERS AND `LEN(CLUSTERS[0][0])` REPRESENTS THE NUMBER OF FEATURES IN EACH DATA POINT.
            2. ITERATE OVER EACH CLUSTER IN THE LIST OF CLUSTERS.
            3. FOR EACH CLUSTER, CALCULATE THE MEAN OF THE DATA POINTS IN THAT CLUSTER ALONG THE FIRST AXIS USING `NP.MEAN(CLUSTER, AXIS=0)`. THIS GIVES THE CENTROID OF THE CLUSTER.
            4. ASSIGN THE CALCULATED CENTROID AS THE VALUE FOR THE CORRESPONDING CLUSTER BY UPDATING THE `CENTROIDS` ARRAY.
            5. RETURN THE `CENTROIDS` ARRAY CONTAINING THE CENTROIDS FOR EACH CLUSTER.
        IN SUMMARY, THE `__GET_CENTROIDS__` FUNCTION CALCULATES THE CENTROID FOR EACH CLUSTER BY TAKING THE MEAN OF THE DATA POINTS IN THE CLUSTER ALONG THE FIRST AXIS. IT PROVIDES A WAY TO COMPUTE THE CENTRE POINT OF EACH CLUSTER, WHICH IS IMPORTANT FOR THE K-MEANS ALGORITHM IN ASSIGNING DATA POINTS TO THEIR NEAREST CLUSTERS."""
        CENTROIDS = np.zeros((len(CLUSTERS), len(CLUSTERS[0][0])))
        for IDX, CLUSTER in enumerate(CLUSTERS):
            CLUSTER_MEAN = np.mean(CLUSTER, axis=0)
            CENTROIDS[IDX] = CLUSTER_MEAN
        return CENTROIDS

    # THE `__IS_CONVERGED__` FUNCTION IS A HELPER FUNCTION USED IN THE K-MEANS CLUSTERING ALGORITHM TO DETERMINE IF THE ALGORITHM HAS CONVERGED. IT COMPARES THE OLD CENTROIDS WITH THE NEW CENTROIDS AND CHECKS IF THEY ARE CLOSE ENOUGH, INDICATING THAT THE ALGORITHM HAS REACHED A STABLE SOLUTION.
    #     1. THE FUNCTION TAKES TWO INPUT PARAMETERS: `OLD_CENTROIDS` AND `NEW_CENTROIDS`, WHICH REPRESENT THE CENTROIDS FROM THE PREVIOUS ITERATION AND THE UPDATED CENTROIDS FROM THE CURRENT ITERATION, RESPECTIVELY.
    #     2. CREATE AN EMPTY LIST `DISTANCES` TO STORE THE DISTANCES BETWEEN THE OLD AND NEW CENTROIDS FOR EACH CLUSTER.
    #     3. ITERATE OVER THE RANGE OF THE NUMBER OF CENTROIDS, WHICH IS THE LENGTH OF `OLD_CENTROIDS` OR `NEW_CENTROIDS`.
    #     4. FOR EACH CENTROID INDEX `IDX`, CALCULATE THE DISTANCE BETWEEN THE OLD AND NEW CENTROIDS USING THE `EUCLIDEAN_DISTANCE` FUNCTION. THIS FUNCTION COMPUTES THE EUCLIDEAN DISTANCE BETWEEN TWO POINTS.
    #     5. APPEND THE CALCULATED DISTANCE TO THE `DISTANCES` LIST.
    #     6. FINALLY, CHECK IF THE SUM OF ALL DISTANCES IN THE `DISTANCES` LIST IS EQUAL TO 0. IF THE SUM IS 0, IT MEANS THAT ALL THE DISTANCES BETWEEN THE OLD AND NEW CENTROIDS ARE CLOSE TO ZERO, INDICATING THAT THE ALGORITHM HAS CONVERGED. RETURN `TRUE` IN THIS CASE.
    #     7. IF THE SUM OF DISTANCES IS NOT EQUAL TO 0, IT MEANS THAT THE ALGORITHM HAS NOT YET CONVERGED. RETURN `FALSE` IN THIS CASE.
    # IN SUMMARY, THE `__IS_CONVERGED__` FUNCTION COMPARES THE DISTANCES BETWEEN THE OLD AND NEW CENTROIDS FOR EACH CLUSTER AND DETERMINES IF THE ALGORITHM HAS CONVERGED. IF THE DISTANCES ARE CLOSE TO ZERO, IT INDICATES CONVERGENCE, AND THE FUNCTION RETURNS `TRUE`. OTHERWISE, IT RETURNS `FALSE`, INDICATING THAT THE ALGORITHM NEEDS TO CONTINUE ITERATING TO FIND A STABLE SOLUTION.
    def __IS_CONVERGED__(OLD_CENTROIDS, NEW_CENTROIDS):
        """THE `__IS_CONVERGED__` FUNCTION IS A HELPER FUNCTION USED IN THE K-MEANS CLUSTERING ALGORITHM TO CHECK IF THE CENTROIDS HAVE CONVERGED, INDICATING THAT THE ALGORITHM HAS REACHED A STABLE SOLUTION. IT COMPARES THE DISTANCES BETWEEN THE OLD AND NEW CENTROIDS FOR EACH CLUSTER AND RETURNS `TRUE` IF THE DISTANCES ARE CLOSE TO ZERO, INDICATING CONVERGENCE. OTHERWISE, IT RETURNS `FALSE`, INDICATING THAT THE ALGORITHM SHOULD CONTINUE ITERATING TO FIND A STABLE SOLUTION."""
        DISTANCES = [EUCLIDEAN_DISTANCE(OLD_CENTROIDS[IDX], NEW_CENTROIDS[IDX]) for IDX in range(len(OLD_CENTROIDS))]
        return sum(DISTANCES) == 0

    # THE `__GET_CLUSTER_LABELS__` FUNCTION IS A HELPER FUNCTION USED IN THE K-MEANS CLUSTERING ALGORITHM TO ASSIGN CLUSTER LABELS TO EACH DATA SAMPLE IN THE DATASET BASED ON THEIR CLOSEST CENTROIDS. IT TAKES THE LIST OF CLUSTERS, WHERE EACH CLUSTER IS REPRESENTED AS A LIST OF SAMPLE INDICES, AND RETURNS A NUMPY ARRAY OF CLUSTER LABELS FOR EACH DATA SAMPLE IN THE DATASET.
    #     1. `LABELS = NP.EMPTY(SUM(LEN(_C) FOR _C IN CLUSTERS))`: THIS LINE INITIALIZES AN EMPTY NUMPY ARRAY TO STORE THE CLUSTER LABELS FOR ALL DATA SAMPLES. THE SIZE OF THIS ARRAY IS EQUAL TO THE TOTAL NUMBER OF DATA SAMPLES IN THE DATASET.
    #     2. `FOR IDX, CLUSTER IN ENUMERATE(CLUSTERS):`: THIS LINE INITIATES A LOOP THAT ITERATES OVER EACH CLUSTER IN THE LIST OF CLUSTERS.
    #     3. `FOR SAMPLE_IDX IN CLUSTER:`: THIS NESTED LOOP ITERATES OVER EACH SAMPLE INDEX IN THE CURRENT CLUSTER.
    #     4. `LABELS[SAMPLE_IDX] = IDX`: FOR EACH SAMPLE INDEX IN THE CURRENT CLUSTER, IT ASSIGNS THE CLUSTER INDEX (`IDX`) AS THE CLUSTER LABEL FOR THAT SAMPLE IN THE `LABELS` ARRAY. SINCE THE `LABELS` ARRAY IS ALIGNED WITH THE ORIGINAL DATASET, THE CLUSTER LABEL IS ASSIGNED TO THE CORRESPONDING DATA SAMPLE.
    #     5. AFTER PROCESSING ALL CLUSTERS AND THEIR SAMPLES, THE FUNCTION RETURNS THE `LABELS` ARRAY CONTAINING THE CLUSTER LABELS FOR EACH DATA SAMPLE IN THE DATASET.
    # IN SUMMARY, THE `__GET_CLUSTER_LABELS__` FUNCTION TAKES A LIST OF CLUSTERS, WHERE EACH CLUSTER CONTAINS THE INDICES OF SAMPLES BELONGING TO THAT CLUSTER, AND RETURNS A NUMPY ARRAY WHERE EACH ELEMENT REPRESENTS THE CLUSTER LABEL FOR THE CORRESPONDING DATA SAMPLE IN THE DATASET. THIS FUNCTION IS AN ESSENTIAL STEP IN THE K-MEANS ALGORITHM TO ASSOCIATE EACH DATA SAMPLE WITH ITS CORRESPONDING CLUSTER AFTER THE CENTROIDS HAVE BEEN DETERMINED.
    def __GET_CLUSTER_LABELS__(CLUSTERS):
        """THE `__GET_CLUSTER_LABELS__` FUNCTION IN THE K-MEANS CLUSTERING ALGORITHM IS RESPONSIBLE FOR ASSIGNING CLUSTER LABELS TO EACH DATA SAMPLE IN THE DATASET BASED ON THEIR CLOSEST CENTROIDS. IT TAKES A LIST OF CLUSTERS, WHERE EACH CLUSTER IS REPRESENTED AS A LIST OF SAMPLES' INDICES AND RETURNS A NUMPY ARRAY OF CLUSTER LABELS FOR EACH DATA SAMPLE.
            1. INITIALIZE AN EMPTY NUMPY ARRAY `LABELS` WITH A SIZE EQUAL TO THE TOTAL NUMBER OF DATA SAMPLES.
            2. ITERATE OVER EACH CLUSTER IN THE LIST OF CLUSTERS.
            3. FOR EACH CLUSTER, ITERATE OVER THE SAMPLE INDICES WITHIN THAT CLUSTER.
            4. ASSIGN THE CLUSTER INDEX AS THE LABEL FOR EACH DATA SAMPLE IN THE `LABELS` ARRAY. THE CLUSTER INDEX REPRESENTS THE CLOSEST CENTROID FOR THAT SAMPLE.
            5. AFTER PROCESSING ALL CLUSTERS AND THEIR SAMPLES, RETURN THE `LABELS` ARRAY CONTAINING THE CLUSTER LABELS FOR EACH DATA SAMPLE.
        IN SUMMARY, THE `__GET_CLUSTER_LABELS__` FUNCTION ASSIGNS CLUSTER LABELS TO EACH DATA SAMPLE BASED ON THEIR CLOSEST CENTROIDS. IT ENABLES THE ASSOCIATION OF DATA SAMPLES WITH THEIR RESPECTIVE CLUSTERS, PROVIDING VALUABLE INFORMATION ABOUT THE CLUSTER MEMBERSHIP OF EACH SAMPLE IN THE DATASET."""
        LABELS = np.empty(sum(len(_C) for _C in CLUSTERS))        
        for IDX, CLUSTER in enumerate(CLUSTERS):
            for SAMPLE_IDX in CLUSTER:
                LABELS[SAMPLE_IDX] = IDX
        return LABELS
    # THE `EUCLIDEAN_DISTANCE` FUNCTION CALCULATES THE EUCLIDEAN DISTANCE BETWEEN TWO POINTS IN A MULTI-DIMENSIONAL SPACE. IT IS A COMMON DISTANCE METRIC USED IN VARIOUS MACHINE LEARNING ALGORITHMS, INCLUDING K-MEANS CLUSTERING.
    #     1. THE FUNCTION TAKES TWO INPUT ARRAYS, `X_1` AND `X_2`, REPRESENTING THE COORDINATES OF TWO POINTS IN THE SAME DIMENSIONAL SPACE.
    #     2. THE DIFFERENCE BETWEEN THE TWO INPUT POINTS IS COMPUTED BY SUBTRACTING `X_2` FROM `X_1`, RESULTING IN A NEW ARRAY REPRESENTING THE VECTOR BETWEEN THE TWO POINTS.
    #     3. THE SQUARE OF EACH ELEMENT IN THE VECTOR IS CALCULATED USING THE `** 2` OPERATOR, EFFECTIVELY SQUARING THE DIFFERENCES ALONG EACH DIMENSION.
    #     4. THE SQUARED DIFFERENCES ALONG EACH DIMENSION ARE SUMMED UP USING THE `NP.SUM` FUNCTION WITH THE `AXIS=0` ARGUMENT, RESULTING IN A SINGLE SCALAR VALUE REPRESENTING THE SUM OF SQUARED DIFFERENCES.
    #     5. THE SQUARE ROOT OF THE SUM OF SQUARED DIFFERENCES IS TAKEN USING THE `NP.SQRT` FUNCTION, YIELDING THE EUCLIDEAN DISTANCE BETWEEN THE TWO POINTS.
    #     6. THE EUCLIDEAN DISTANCE IS RETURNED AS THE OUTPUT OF THE FUNCTION.
    # IN SUMMARY, THE `EUCLIDEAN_DISTANCE` FUNCTION CALCULATES THE EUCLIDEAN DISTANCE BETWEEN TWO POINTS BY FINDING THE SQUARE ROOT OF THE SUM OF SQUARED DIFFERENCES ALONG EACH DIMENSION. IT PROVIDES A MEASURE OF SIMILARITY OR DISSIMILARITY BETWEEN POINTS IN A MULTI-DIMENSIONAL SPACE, WHICH IS USED IN VARIOUS ALGORITHMS FOR CLUSTERING, CLASSIFICATION, AND OTHER TASKS.
    def EUCLIDEAN_DISTANCE(X_1, X_2):
        """THE `EUCLIDEAN_DISTANCE` FUNCTION CALCULATES THE EUCLIDEAN DISTANCE BETWEEN TWO POINTS IN A MULTI-DIMENSIONAL SPACE. IT TAKES TWO INPUT ARRAYS REPRESENTING THE COORDINATES OF THE POINTS AND COMPUTES THE SQUARE ROOT OF THE SUM OF SQUARED DIFFERENCES ALONG EACH DIMENSION. THE RESULTING VALUE REPRESENTS THE DISTANCE BETWEEN THE TWO POINTS. THIS DISTANCE METRIC IS COMMONLY USED TO MEASURE THE SIMILARITY OR DISSIMILARITY BETWEEN POINTS IN VARIOUS MACHINE LEARNING ALGORITHMS AND IS PARTICULARLY RELEVANT IN THE CONTEXT OF K-MEANS CLUSTERING."""
        return np.sqrt(np.sum((X_1 - X_2) ** 2, axis=0))

    np.random.seed(42)
    N_SAMPLES, _ = X.shape
    CENTROIDS = X[np.random.choice(N_SAMPLES, K, replace=False)]
    CLUSTERS = [[] for _ in range(K)]
    for _ in range(MAX_ITERATIONS):
        NEW_CLUSTERS = __CREATE_CLUSTERS__(X, CENTROIDS)
        NEW_CENTROIDS = __GET_CENTROIDS__(NEW_CLUSTERS)
        if __IS_CONVERGED__(CENTROIDS, NEW_CENTROIDS):
            break
        CLUSTERS = NEW_CLUSTERS
        CENTROIDS = NEW_CENTROIDS
    LABELS = __GET_CLUSTER_LABELS__(CLUSTERS)
    return LABELS