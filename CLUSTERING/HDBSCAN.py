import numpy as np

# THE `HDBSCAN` FUNCTION IS AN IMPLEMENTATION OF THE HDBSCAN (HIERARCHICAL DENSITY-BASED SPATIAL CLUSTERING OF APPLICATIONS WITH NOISE) ALGORITHM. HDBSCAN IS A DENSITY-BASED CLUSTERING ALGORITHM THAT IDENTIFIES CLUSTERS OF VARYING DENSITIES IN A DATASET, WHILE ALSO CAPTURING THE PRESENCE OF OUTLIERS OR NOISE POINTS.
#     1. IT DEFINES THE `HDBSCAN` FUNCTION THAT TAKES TWO PARAMETERS: `X` AND `MIN_SAMPLES`. `X` IS A NUMPY ARRAY REPRESENTING THE INPUT DATASET, WHERE EACH ROW CORRESPONDS TO A SAMPLE, AND THE COLUMNS REPRESENT DIFFERENT FEATURES OR DIMENSIONS OF THE SAMPLES. `MIN_SAMPLES` IS AN OPTIONAL PARAMETER THAT DETERMINES THE MINIMUM NUMBER OF SAMPLES REQUIRED TO FORM A DENSE REGION.
#     2. WITHIN THE `HDBSCAN` FUNCTION, THERE ARE SEVERAL NESTED HELPER FUNCTIONS THAT PERFORM SPECIFIC STEPS OF THE HDBSCAN ALGORITHM. THESE HELPER FUNCTIONS ARE PREFIXED WITH DOUBLE UNDERSCORES (`__`) TO INDICATE THEIR INTERNAL USE AND ARE NOT INTENDED TO BE CALLED DIRECTLY FROM OUTSIDE THE `HDBSCAN` FUNCTION.
#     3. THE FIRST HELPER FUNCTION IS `__COMPUTE_CORE_DISTANCES__`. IT CALCULATES THE CORE DISTANCES FOR EACH SAMPLE IN THE DATASET `X`. CORE DISTANCE IS DEFINED AS THE DISTANCE TO THE `MIN_SAMPLES`-TH NEAREST NEIGHBOR. IT USES THE `PAIRWISE_DISTANCES` FUNCTION TO COMPUTE THE PAIRWISE DISTANCES BETWEEN ALL SAMPLES. THE DISTANCES ARE THEN SORTED, AND THE `MIN_SAMPLES`-TH DISTANCE FOR EACH SAMPLE IS EXTRACTED AS THE CORE DISTANCE.
#     4. THE SECOND HELPER FUNCTION IS `__COMPUTE_NEIGHBOURS__`. IT DETERMINES THE NEIGHBORS OF EACH SAMPLE BASED ON THE CORE DISTANCES. IT USES THE `PAIRWISE_DISTANCES` FUNCTION AGAIN TO COMPUTE THE PAIRWISE DISTANCES. IT SELECTS THE NEIGHBORS FOR EACH SAMPLE BY FINDING THE INDICES OF SAMPLES WHOSE DISTANCES ARE LESS THAN OR EQUAL TO THE CORE DISTANCE OF THAT SAMPLE.
#     5. THE THIRD HELPER FUNCTION IS `__CONDENSE_TREE__`. IT CONSTRUCTS A CONDENSED TREE REPRESENTATION OF THE CLUSTERS BY ITERATIVELY MERGING PAIRS OF SAMPLES BASED ON THEIR CORE DISTANCES AND PROXIMITY. IT INITIALIZES AN EMPTY DICTIONARY `CONDENSED_TREE` TO STORE THE MERGED CLUSTERS. IT ITERATES OVER EACH SAMPLE AND ITS CORRESPONDING NEIGHBORS. FOR EACH SAMPLE, IT SELECTS THE NEIGHBOR WITH THE MINIMUM CORE DISTANCE AND ADDS AN EDGE BETWEEN THEM IN THE CONDENSED TREE, ALONG WITH THE LENGTH OF THE EDGE. THIS PROCESS CONTINUES UNTIL ALL SAMPLES HAVE BEEN PROCESSED.
#     6. THE FOURTH HELPER FUNCTION IS `__EXTRACT_CLUSTERS__`. IT EXTRACTS THE FINAL CLUSTERS FROM THE CONDENSED TREE REPRESENTATION. IT INITIALIZES AN ARRAY `LABELS` TO STORE THE CLUSTER LABELS FOR EACH SAMPLE, INITIALLY SET TO -1. IT ASSIGNS A UNIQUE CLUSTER ID TO EACH CLUSTER. IT ITERATES OVER THE EDGES OF THE CONDENSED TREE IN ASCENDING ORDER OF EDGE LENGTH. FOR EACH EDGE, IT CHECKS THE LABELS OF THE SAMPLES CONNECTED BY THE EDGE. IF BOTH SAMPLES ARE UNASSIGNED (-1), IT ASSIGNS THEM THE SAME CLUSTER ID. IF ONE SAMPLE IS UNASSIGNED, IT ASSIGNS IT THE CLUSTER ID OF THE OTHER SAMPLE. IF BOTH SAMPLES ALREADY HAVE ASSIGNED LABELS AND THE LABELS ARE DIFFERENT, IT MERGES THE CLUSTERS BY ASSIGNING THE MINIMUM LABEL TO ALL SAMPLES WITH EITHER LABEL. FINALLY, IT APPLIES A POST-PROCESSING STEP USING THE `__POST_PROCESS_LABELS__` FUNCTION TO RELABEL THE CLUSTERS SEQUENTIALLY STARTING FROM ZERO.
#     7. THE FIFTH HELPER FUNCTION IS `__POST_PROCESS_LABELS__`. IT RELABELS THE CLUSTER IDS TO ENSURE THEY ARE SEQUENTIAL AND STARTING FROM ZERO. IT USES THE `NP.UNIQUE` FUNCTION TO OBTAIN THE UNIQUE CLUSTER LABELS IN THE `LABELS` ARRAY. IT THEN ITERATES OVER THE UNIQUE LABELS AND ASSIGNS A NEW LABEL INDEX TO ALL SAMPLES WITH THE CORRESPONDING LABEL, RESULTING IN A NEW ARRAY OF RELABELLED CLUSTER IDS.
#     8. AFTER THE HELPER FUNCTIONS, THE `N_SAMPLES` VARIABLE IS SET TO THE NUMBER OF SAMPLES IN THE INPUT DATASET `X`. THIS VALUE IS USED IN SUBSEQUENT CALCULATIONS.
#     9. THE `CORE_DISTANCES` VARIABLE IS COMPUTED BY CALLING THE `__COMPUTE_CORE_DISTANCES__` FUNCTION, PASSING THE DATASET `X` AS AN ARGUMENT.
#     10. THE `NEIGHBOURS` VARIABLE IS COMPUTED BY CALLING THE `__COMPUTE_NEIGHBOURS__` FUNCTION, PASSING THE DATASET `X` AND THE `CORE_DISTANCES` AS ARGUMENTS.
#     11. THE `CONDENSED_TREE` VARIABLE IS COMPUTED BY CALLING THE `__CONDENSE_TREE__` FUNCTION, PASSING THE DATASET `X`, `NEIGHBOURS`, AND `CORE_DISTANCES` AS ARGUMENTS.
#     12. THE `LABELS` VARIABLE IS COMPUTED BY CALLING THE `__EXTRACT_CLUSTERS__` FUNCTION, PASSING THE `CONDENSED_TREE`, AND `N_SAMPLES` AS ARGUMENTS.
#     13. FINALLY, THE `LABELS` ARRAY, REPRESENTING THE CLUSTER ASSIGNMENTS FOR EACH SAMPLE, IS RETURNED AS THE OUTPUT OF THE `HDBSCAN` FUNCTION.
# IN SUMMARY, THE `HDBSCAN` FUNCTION APPLIES THE HDBSCAN ALGORITHM TO A GIVEN DATASET BY CALCULATING THE CORE DISTANCES, DETERMINING NEIGHBORS, CONSTRUCTING A CONDENSED TREE, AND EXTRACTING THE FINAL CLUSTERS. IT PROVIDES A FLEXIBLE AND EFFICIENT WAY TO PERFORM DENSITY-BASED CLUSTERING, CAPTURING CLUSTERS OF VARYING DENSITIES WHILE ALSO ACCOUNTING FOR NOISE POINTS OR OUTLIERS.


def HDBSCAN(X, MIN_SAMPLES=5):
    """THE `HDBSCAN` FUNCTION IMPLEMENTS THE HDBSCAN ALGORITHM, WHICH IS A DENSITY-BASED CLUSTERING ALGORITHM FOR IDENTIFYING CLUSTERS OF VARYING DENSITIES IN A DATASET.
        1. DENSITY-BASED CLUSTERING: HDBSCAN IS A DENSITY-BASED CLUSTERING ALGORITHM, MEANING IT GROUPS TOGETHER SAMPLES BASED ON THEIR DENSITY IN THE FEATURE SPACE. IT AIMS TO CAPTURE CLUSTERS OF DIFFERENT SHAPES AND SIZES, WHILE ALSO ACCOUNTING FOR NOISE OR OUTLIER POINTS.
        2. CORE DISTANCES: THE ALGORITHM CALCULATES CORE DISTANCES FOR EACH SAMPLE, WHICH REPRESENT THE DISTANCE TO ITS `MIN_SAMPLES`-TH NEAREST NEIGHBOR. CORE DISTANCES HELP IDENTIFY DENSE REGIONS WITHIN THE DATASET.
        3. NEIGHBORS: NEIGHBORS OF A SAMPLE ARE DETERMINED BASED ON THEIR DISTANCES TO EACH OTHER. SAMPLES WITHIN A CERTAIN DISTANCE THRESHOLD, DETERMINED BY THE CORE DISTANCE, ARE CONSIDERED NEIGHBORS OF A GIVEN SAMPLE.
        4. CONDENSED TREE: HDBSCAN CONSTRUCTS A CONDENSED TREE THAT REPRESENTS THE MERGING OF CLUSTERS BASED ON THEIR CORE DISTANCES AND PROXIMITY. THE TREE CAPTURES THE HIERARCHY OF CLUSTERS AND THEIR RELATIONSHIPS.
        5. CLUSTER EXTRACTION: THE CONDENSED TREE IS USED TO EXTRACT THE FINAL CLUSTERS. CLUSTERS ARE IDENTIFIED BY MERGING SAMPLES BASED ON THEIR CORE DISTANCES AND PROXIMITY. SAMPLES WITH SIMILAR OR OVERLAPPING CLUSTERS ARE ASSIGNED THE SAME LABEL.
        6. POST-PROCESSING: THE CLUSTER LABELS ARE POST-PROCESSED TO ENSURE SEQUENTIAL AND ZERO-BASED INDEXING OF THE CLUSTERS. THIS STEP SIMPLIFIES FURTHER ANALYSIS AND INTERPRETATION OF THE CLUSTERING RESULTS.
        7. PAIRWISE DISTANCES: THE ALGORITHM RELIES ON PAIRWISE DISTANCES BETWEEN SAMPLES. PAIRWISE DISTANCES QUANTIFY THE SIMILARITY OR DISSIMILARITY BETWEEN SAMPLES BASED ON THEIR FEATURES OR DIMENSIONS.
        8. EUCLIDEAN DISTANCE: THE PAIRWISE DISTANCES ARE TYPICALLY CALCULATED USING THE EUCLIDEAN DISTANCE METRIC, WHICH MEASURES THE STRAIGHT-LINE DISTANCE BETWEEN TWO POINTS IN THE FEATURE SPACE.
        9. INPUT DATASET: THE `HDBSCAN` FUNCTION TAKES A DATASET AS INPUT, WHERE EACH ROW REPRESENTS A SAMPLE AND THE COLUMNS CORRESPOND TO DIFFERENT FEATURES OR DIMENSIONS OF THE SAMPLES.
        10. CLUSTER LABELS: THE OUTPUT OF THE `HDBSCAN` FUNCTION IS AN ARRAY OF CLUSTER LABELS, WHERE EACH LABEL INDICATES THE CLUSTER ASSIGNMENT OF THE CORRESPONDING SAMPLE IN THE INPUT DATASET. SAMPLES WITH THE SAME LABEL BELONG TO THE SAME CLUSTER.
    IN SUMMARY, THE `HDBSCAN` FUNCTION APPLIES THE HDBSCAN ALGORITHM TO PERFORM DENSITY-BASED CLUSTERING BY CALCULATING CORE DISTANCES, DETERMINING NEIGHBORS, CONSTRUCTING A CONDENSED TREE, AND EXTRACTING CLUSTERS. IT PROVIDES A FLEXIBLE AND EFFECTIVE APPROACH FOR DISCOVERING CLUSTERS OF VARYING DENSITIES AND CAPTURING THE PRESENCE OF OUTLIERS OR NOISE POINTS IN A DATASET."""

    # THE `__COMPUTE_CORE_DISTANCES__` FUNCTION IS A HELPER FUNCTION WITHIN THE `HDBSCAN` ALGORITHM. ITS PURPOSE IS TO CALCULATE THE CORE DISTANCES FOR EACH SAMPLE IN THE INPUT DATASET `X`.
    #     1. THE FUNCTION TAKES THE DATASET `X` AS INPUT.
    #     2. IT BEGINS BY CALLING THE `PAIRWISE_DISTANCES` FUNCTION, WHICH COMPUTES THE PAIRWISE DISTANCES BETWEEN ALL SAMPLES IN `X`. THE PAIRWISE DISTANCES PROVIDE A MEASURE OF SIMILARITY OR DISSIMILARITY BETWEEN PAIRS OF SAMPLES BASED ON THEIR FEATURES OR DIMENSIONS.
    #     3. THE RESULTING DISTANCE MATRIX IS STORED IN THE `DISTANCES` VARIABLE.
    #     4. NEXT, THE `SORTED_DISTANCES` ARRAY IS CREATED BY SORTING THE `DISTANCES` MATRIX ALONG THE ROWS (AXIS 0). SORTING THE DISTANCES ALLOWS US TO ACCESS THE `MIN_SAMPLES`-TH NEAREST NEIGHBOR DISTANCE FOR EACH SAMPLE.
    #     5. THE `MIN_SAMPLES - 1` INDEX IS USED TO EXTRACT THE `MIN_SAMPLES`-TH NEAREST NEIGHBOR DISTANCES FROM THE SORTED DISTANCES. THIS VALUE REPRESENTS THE CORE DISTANCE FOR EACH SAMPLE.
    #     6. THE CORE DISTANCES ARE STORED IN THE `CORE_DISTANCES` ARRAY.
    #     7. FINALLY, THE `CORE_DISTANCES` ARRAY, CONTAINING THE CORE DISTANCES FOR EACH SAMPLE IN THE DATASET, IS RETURNED AS THE OUTPUT OF THE `__COMPUTE_CORE_DISTANCES__` FUNCTION.
    # IN SUMMARY, THE `__COMPUTE_CORE_DISTANCES__` FUNCTION CALCULATES THE CORE DISTANCES FOR EACH SAMPLE IN THE DATASET BY UTILIZING THE `PAIRWISE_DISTANCES` FUNCTION TO COMPUTE THE PAIRWISE DISTANCES BETWEEN ALL SAMPLES. IT THEN EXTRACTS THE `MIN_SAMPLES`-TH NEAREST NEIGHBOR DISTANCES FROM THE SORTED DISTANCES, RESULTING IN AN ARRAY OF CORE DISTANCES. THE CORE DISTANCES PROVIDE A MEASURE OF DENSITY FOR EACH SAMPLE, INDICATING THE DISTANCE TO ITS `MIN_SAMPLES`-TH NEAREST NEIGHBOR. THESE CORE DISTANCES ARE SUBSEQUENTLY USED IN OTHER STEPS OF THE HDBSCAN ALGORITHM, SUCH AS DETERMINING NEIGHBORS AND CONSTRUCTING THE CONDENSED TREE.
    def __COMPUTE_CORE_DISTANCES__(X):
        """THE `__COMPUTE_CORE_DISTANCES__` FUNCTION IS A HELPER FUNCTION WITHIN THE HDBSCAN ALGORITHM THAT CALCULATES THE CORE DISTANCES FOR EACH SAMPLE IN THE DATASET.
            1. CORE DISTANCES: THE FUNCTION CALCULATES THE CORE DISTANCE FOR EACH SAMPLE, WHICH REPRESENTS THE DISTANCE TO ITS `MIN_SAMPLES`-TH NEAREST NEIGHBOR. CORE DISTANCES HELP IDENTIFY DENSE REGIONS WITHIN THE DATASET.
            2. PAIRWISE DISTANCES: THE FUNCTION RELIES ON THE `PAIRWISE_DISTANCES` FUNCTION TO COMPUTE THE PAIRWISE DISTANCES BETWEEN ALL SAMPLES. PAIRWISE DISTANCES QUANTIFY THE SIMILARITY OR DISSIMILARITY BETWEEN PAIRS OF SAMPLES BASED ON THEIR FEATURES OR DIMENSIONS.
            3. SORTING: THE FUNCTION SORTS THE PAIRWISE DISTANCES TO OBTAIN THE NEAREST NEIGHBOR DISTANCES FOR EACH SAMPLE. SORTING ALLOWS ACCESSING THE `MIN_SAMPLES`-TH NEAREST NEIGHBOR DISTANCE, WHICH IS USED AS THE CORE DISTANCE.
            4. INPUT DATASET: THE FUNCTION TAKES THE DATASET `X` AS INPUT, WHERE EACH ROW REPRESENTS A SAMPLE AND THE COLUMNS CORRESPOND TO DIFFERENT FEATURES OR DIMENSIONS OF THE SAMPLES.
            5. CORE DISTANCES ARRAY: THE FUNCTION RETURNS AN ARRAY OF CORE DISTANCES, WHERE EACH VALUE REPRESENTS THE CORE DISTANCE FOR THE CORRESPONDING SAMPLE IN THE DATASET.
        IN SUMMARY, THE `__COMPUTE_CORE_DISTANCES__` FUNCTION CALCULATES THE CORE DISTANCES FOR EACH SAMPLE BY COMPUTING THE PAIRWISE DISTANCES BETWEEN ALL SAMPLES, SORTING THE DISTANCES, AND EXTRACTING THE `MIN_SAMPLES`-TH NEAREST NEIGHBOR DISTANCE FOR EACH SAMPLE. CORE DISTANCES HELP IDENTIFY DENSE REGIONS IN THE DATASET, WHICH ARE CRUCIAL FOR SUBSEQUENT STEPS IN THE HDBSCAN ALGORITHM."""
        DISTANCES = PAIRWISE_DISTANCES(
            X)  # THE `PAIRWISE_DISTANCES` FUNCTION CALCULATES THE PAIRWISE DISTANCES BETWEEN ALL SAMPLES IN THE DATASET.
        # THE `SORTED_DISTANCES` ARRAY IS CREATED BY SORTING THE `DISTANCES` MATRIX ALONG THE ROWS (AXIS 0). SORTING THE DISTANCES ALLOWS US TO ACCESS THE `MIN_SAMPLES`-TH NEAREST NEIGHBOR DISTANCE FOR EACH SAMPLE.
        SORTED_DISTANCES = np.sort(DISTANCES, axis=0)
        # THE `MIN_SAMPLES - 1` INDEX IS USED TO EXTRACT THE `MIN_SAMPLES`-TH NEAREST NEIGHBOR DISTANCES FROM THE SORTED DISTANCES. THIS VALUE REPRESENTS THE CORE DISTANCE FOR EACH SAMPLE.
        CORE_DISTANCES = SORTED_DISTANCES[MIN_SAMPLES - 1]
        # THE CORE DISTANCES ARE STORED IN THE `CORE_DISTANCES` ARRAY.
        return CORE_DISTANCES

    # THE `__COMPUTE_NEIGHBOURS__` FUNCTION IS ANOTHER HELPER FUNCTION WITHIN THE HDBSCAN ALGORITHM. ITS PURPOSE IS TO DETERMINE THE NEIGHBORS OF EACH SAMPLE BASED ON THEIR CORE DISTANCES.
    #     1. THE FUNCTION TAKES TWO PARAMETERS AS INPUT: THE DATASET `X` AND THE ARRAY OF CORE DISTANCES `CORE_DISTANCES`.
    #     2. IT BEGINS BY CALLING THE `PAIRWISE_DISTANCES` FUNCTION, WHICH COMPUTES THE PAIRWISE DISTANCES BETWEEN ALL SAMPLES IN `X`. THE PAIRWISE DISTANCES PROVIDE A MEASURE OF SIMILARITY OR DISSIMILARITY BETWEEN PAIRS OF SAMPLES BASED ON THEIR FEATURES OR DIMENSIONS.
    #     3. THE RESULTING DISTANCE MATRIX IS USED TO IDENTIFY THE NEIGHBORS OF EACH SAMPLE.
    #     4. FOR EACH SAMPLE, THE FUNCTION SELECTS ITS NEIGHBORS BY FINDING THE INDICES OF SAMPLES WHOSE DISTANCES ARE LESS THAN OR EQUAL TO THE CORE DISTANCE OF THAT SAMPLE. THIS IS DONE USING THE `NP.ARGWHERE` FUNCTION, WHICH RETURNS THE INDICES WHERE A CERTAIN CONDITION IS SATISFIED.
    #     5. THE RESULTING INDICES REPRESENT THE NEIGHBORING SAMPLES FOR EACH SAMPLE AND ARE STORED IN THE `NEIGHBOURS` ARRAY.
    #     6. FINALLY, THE `NEIGHBOURS` ARRAY, CONTAINING THE INDICES OF NEIGHBORS FOR EACH SAMPLE IN THE DATASET, IS RETURNED AS THE OUTPUT OF THE `__COMPUTE_NEIGHBOURS__` FUNCTION.
    # IN SUMMARY, THE `__COMPUTE_NEIGHBOURS__` FUNCTION DETERMINES THE NEIGHBORS OF EACH SAMPLE IN THE DATASET BY COMPARING THEIR DISTANCES TO THE CORE DISTANCES. IT UTILIZES THE `PAIRWISE_DISTANCES` FUNCTION TO COMPUTE THE PAIRWISE DISTANCES, AND THEN SELECTS THE NEIGHBORS BASED ON THE CONDITION THAT THEIR DISTANCES ARE LESS THAN OR EQUAL TO THE CORE DISTANCE. THE RESULTING INDICES OF THE NEIGHBORING SAMPLES ARE STORED IN THE `NEIGHBOURS` ARRAY, WHICH IS SUBSEQUENTLY USED IN LATER STAGES OF THE HDBSCAN ALGORITHM.
    def __COMPUTE_NEIGHBOURS__(X, CORE_DISTANCES):
        """THE `__COMPUTE_NEIGHBOURS__` FUNCTION IS A HELPER FUNCTION WITHIN THE HDBSCAN ALGORITHM THAT DETERMINES THE NEIGHBORS OF EACH SAMPLE BASED ON THEIR CORE DISTANCES.
            1. CORE DISTANCES: THE FUNCTION UTILIZES THE CORE DISTANCES, WHICH REPRESENT THE DISTANCE TO THE `MIN_SAMPLES`-TH NEAREST NEIGHBOR FOR EACH SAMPLE. CORE DISTANCES ARE CRUCIAL FOR IDENTIFYING DENSE REGIONS WITHIN THE DATASET.
            2. PAIRWISE DISTANCES: THE FUNCTION CALLS THE `PAIRWISE_DISTANCES` FUNCTION TO COMPUTE THE PAIRWISE DISTANCES BETWEEN ALL SAMPLES. PAIRWISE DISTANCES MEASURE THE SIMILARITY OR DISSIMILARITY BETWEEN PAIRS OF SAMPLES BASED ON THEIR FEATURES OR DIMENSIONS.
            3. NEIGHBOR DETERMINATION: FOR EACH SAMPLE, THE FUNCTION IDENTIFIES ITS NEIGHBORS BY COMPARING THEIR DISTANCES TO THE SAMPLE'S CORE DISTANCE. SAMPLES WITH DISTANCES LESS THAN OR EQUAL TO THE CORE DISTANCE ARE CONSIDERED NEIGHBORS.
            4. INPUT DATASET: THE FUNCTION TAKES THE DATASET `X` AS INPUT, WHERE EACH ROW REPRESENTS A SAMPLE AND THE COLUMNS CORRESPOND TO DIFFERENT FEATURES OR DIMENSIONS OF THE SAMPLES.
            5. NEIGHBORS ARRAY: THE FUNCTION RETURNS AN ARRAY THAT CONTAINS THE INDICES OF NEIGHBORING SAMPLES FOR EACH SAMPLE IN THE DATASET. THESE INDICES REPRESENT THE SAMPLES' POSITIONS WITHIN THE DATASET.
        IN SUMMARY, THE `__COMPUTE_NEIGHBOURS__` FUNCTION DETERMINES THE NEIGHBORS OF EACH SAMPLE BASED ON THEIR CORE DISTANCES BY COMPARING THE PAIRWISE DISTANCES TO THE CORE DISTANCES. IT USES THE `PAIRWISE_DISTANCES` FUNCTION TO COMPUTE THE DISTANCES, IDENTIFIES NEIGHBORS BASED ON A CONDITION, AND RETURNS AN ARRAY CONTAINING THE INDICES OF THE NEIGHBORING SAMPLES FOR EACH SAMPLE. THE NEIGHBOR INFORMATION IS ESSENTIAL FOR SUBSEQUENT STEPS IN THE HDBSCAN ALGORITHM."""
        NEIGHBOURS = np.argwhere(PAIRWISE_DISTANCES(X) <= CORE_DISTANCES)[
            :, 1]  # THE `NEIGHBOURS` ARRAY IS CREATED BY FINDING THE INDICES OF SAMPLES WHOSE DISTANCES ARE LESS THAN OR EQUAL TO THE CORE DISTANCE OF THAT SAMPLE. THIS IS DONE USING THE `NP.ARGWHERE` FUNCTION, WHICH RETURNS THE INDICES WHERE A CERTAIN CONDITION IS SATISFIED.
        # THE `NEIGHBOURS` ARRAY, CONTAINING THE INDICES OF NEIGHBORS FOR EACH SAMPLE IN THE DATASET, IS RETURNED AS THE OUTPUT OF THE `__COMPUTE_NEIGHBOURS__` FUNCTION.
        return NEIGHBOURS

    # THE `__CONDENSE_TREE__` FUNCTION IS A HELPER FUNCTION WITHIN THE HDBSCAN ALGORITHM. ITS PURPOSE IS TO CONSTRUCT A CONDENSED TREE REPRESENTATION OF THE CLUSTERS BY MERGING PAIRS OF SAMPLES BASED ON THEIR CORE DISTANCES AND PROXIMITY.
    #     1. THE FUNCTION TAKES THREE PARAMETERS AS INPUT: THE DATASET `X`, THE ARRAY OF NEIGHBORS `NEIGHBOURS`, AND THE ARRAY OF CORE DISTANCES `CORE_DISTANCES`.
    #     2. IT INITIALIZES AN EMPTY DICTIONARY `CONDENSED_TREE` THAT WILL STORE THE MERGED CLUSTERS. THE CONDENSED TREE REPRESENTATION CAPTURES THE HIERARCHY OF CLUSTERS AND THEIR RELATIONSHIPS.
    #     3. THE FUNCTION ITERATES OVER EACH SAMPLE IN THE DATASET `X` USING THE `ENUMERATE` FUNCTION, WHICH PROVIDES BOTH THE INDEX AND THE SAMPLE ITSELF.
    #     4. FOR EACH SAMPLE, IT SELECTS ITS CORRESPONDING NEIGHBORS FROM THE `NEIGHBOURS` ARRAY. THE NEIGHBORS ARE IDENTIFIED BY CHECKING WHICH INDICES IN THE `NEIGHBOURS` ARRAY ARE EQUAL TO THE INDEX OF THE CURRENT SAMPLE.
    #     5. IF THERE ARE NEIGHBORS FOR THE CURRENT SAMPLE, THE FUNCTION PROCEEDS TO FIND THE NEAREST NEIGHBOR BASED ON THEIR CORE DISTANCES. IT CALCULATES THE MINIMUM DISTANCE INDEX USING `NP.ARGMIN` ON THE `CORE_DISTANCES` ARRAY, CONSIDERING ONLY THE CORE DISTANCES OF THE NEIGHBORS.
    #     6. THE NEAREST NEIGHBOR INDEX IS USED TO DETERMINE THE LENGTH OF THE EDGE THAT CONNECTS THE CURRENT SAMPLE TO ITS NEAREST NEIGHBOR. THE LENGTH IS OBTAINED FROM THE `CORE_DISTANCES` ARRAY USING THE NEAREST NEIGHBOR INDEX.
    #     7. THE EDGE BETWEEN THE CURRENT SAMPLE AND ITS NEAREST NEIGHBOR, ALONG WITH THE EDGE LENGTH, IS ADDED TO THE `CONDENSED_TREE` DICTIONARY AS A KEY-VALUE PAIR. THE KEY REPRESENTS THE PAIR OF INDICES (CURRENT SAMPLE INDEX, NEAREST NEIGHBOR INDEX), AND THE VALUE REPRESENTS THE EDGE LENGTH.
    #     8. THE PROCESS REPEATS FOR EACH SAMPLE IN THE DATASET, CONSIDERING ITS NEIGHBORS AND FINDING THE NEAREST NEIGHBOR WITH THE MINIMUM CORE DISTANCE. THE RESULTING EDGES AND THEIR LENGTHS ARE ADDED TO THE `CONDENSED_TREE` DICTIONARY.
    #     9. FINALLY, THE `CONDENSED_TREE` DICTIONARY, CONTAINING THE MERGED CLUSTERS REPRESENTED AS EDGES AND THEIR LENGTHS, IS RETURNED AS THE OUTPUT OF THE `__CONDENSE_TREE__` FUNCTION.
    # IN SUMMARY, THE `__CONDENSE_TREE__` FUNCTION CONSTRUCTS A CONDENSED TREE REPRESENTATION OF THE CLUSTERS BY ITERATIVELY MERGING PAIRS OF SAMPLES BASED ON THEIR CORE DISTANCES AND PROXIMITY. IT CREATES A DICTIONARY, WHERE EACH KEY-VALUE PAIR REPRESENTS AN EDGE BETWEEN TWO SAMPLES AND THE LENGTH OF THE EDGE. THE RESULTING DICTIONARY CAPTURES THE HIERARCHY OF CLUSTERS AND THEIR RELATIONSHIPS, PROVIDING A COMPACT REPRESENTATION OF THE CLUSTERING STRUCTURE. THE CONDENSED TREE IS SUBSEQUENTLY USED IN LATER STAGES OF THE HDBSCAN ALGORITHM FOR CLUSTER EXTRACTION AND LABEL ASSIGNMENT.
    def __CONDENSE_TREE__(X, NEIGHBOURS, CORE_DISTANCES):
        """THE `__CONDENSE_TREE__` FUNCTION IS A HELPER FUNCTION WITHIN THE HDBSCAN ALGORITHM THAT CONSTRUCTS A CONDENSED TREE REPRESENTATION OF CLUSTERS BY MERGING SAMPLES BASED ON THEIR CORE DISTANCES.
            1. CONDENSED TREE: THE FUNCTION BUILDS A CONDENSED TREE THAT CAPTURES THE HIERARCHICAL RELATIONSHIP BETWEEN CLUSTERS. THE CONDENSED TREE REPRESENTS THE MERGING OF SAMPLES BASED ON THEIR CORE DISTANCES AND PROXIMITY.
            2. MERGING SAMPLES: THE FUNCTION ITERATES OVER EACH SAMPLE IN THE DATASET AND IDENTIFIES ITS NEIGHBORS. IT THEN SELECTS THE NEAREST NEIGHBOR BASED ON THEIR CORE DISTANCES.
            3. EDGE CREATION: FOR EACH SAMPLE AND ITS NEAREST NEIGHBOR, THE FUNCTION CREATES AN EDGE IN THE CONDENSED TREE. THE EDGE REPRESENTS THE CONNECTION BETWEEN THE SAMPLES, AND ITS LENGTH IS DETERMINED BY THE CORE DISTANCE OF THE NEAREST NEIGHBOR.
            4. CONDENSED TREE REPRESENTATION: THE FUNCTION STORES THE MERGED CLUSTERS AS KEY-VALUE PAIRS IN A DICTIONARY. EACH PAIR CONSISTS OF THE INDICES OF THE CONNECTED SAMPLES AND THE LENGTH OF THE EDGE BETWEEN THEM.
            5. INPUT DATASET: THE FUNCTION TAKES THE DATASET `X` AS INPUT, WHERE EACH ROW REPRESENTS A SAMPLE AND THE COLUMNS CORRESPOND TO DIFFERENT FEATURES OR DIMENSIONS OF THE SAMPLES.
            6. CONDENSED TREE DICTIONARY: THE FUNCTION RETURNS A DICTIONARY, KNOWN AS THE CONDENSED TREE, WHICH REPRESENTS THE MERGED CLUSTERS AS EDGES AND THEIR LENGTHS.
        IN SUMMARY, THE `__CONDENSE_TREE__` FUNCTION CONSTRUCTS A CONDENSED TREE REPRESENTATION OF CLUSTERS BY MERGING SAMPLES BASED ON THEIR CORE DISTANCES. IT CREATES A DICTIONARY THAT CAPTURES THE HIERARCHICAL STRUCTURE OF THE CLUSTERS. THE CONDENSED TREE PROVIDES A CONCISE REPRESENTATION OF THE CLUSTERING RELATIONSHIPS AND IS USED IN SUBSEQUENT STEPS OF THE HDBSCAN ALGORITHM FOR CLUSTER EXTRACTION AND ANALYSIS."""
        CONDENSED_TREE = {}  # INITIALIZE AN EMPTY DICTIONARY TO STORE THE MERGED CLUSTERS
        for IDX, _ in enumerate(X):  # ITERATE OVER EACH SAMPLE IN THE DATASET
            # SELECT THE NEIGHBORS OF THE CURRENT SAMPLE
            NEIGHBOURS = NEIGHBOURS[NEIGHBOURS == IDX]
            if len(NEIGHBOURS) > 0:  # IF THERE ARE NEIGHBORS FOR THE CURRENT SAMPLE
                # FIND THE NEAREST NEIGHBOR BASED ON THEIR CORE DISTANCES
                MIN_DISTANCE_IDX = np.argmin(CORE_DISTANCES[NEIGHBOURS])
                # GET THE INDEX OF THE NEAREST NEIGHBOR
                NEAREST_NEIGHBOUR = NEIGHBOURS[MIN_DISTANCE_IDX]
                # GET THE LENGTH OF THE EDGE BETWEEN THE CURRENT SAMPLE AND ITS NEAREST NEIGHBOR
                EDGE_LENGTH = CORE_DISTANCES[NEAREST_NEIGHBOUR]
                # ADD THE EDGE BETWEEN THE CURRENT SAMPLE AND ITS NEAREST NEIGHBOR TO THE CONDENSED TREE
                CONDENSED_TREE[(IDX, NEAREST_NEIGHBOUR)] = EDGE_LENGTH
        return CONDENSED_TREE  # RETURN THE CONDENSED TREE REPRESENTATION OF THE CLUSTERS

    # THE `__EXTRACT_CLUSTERS__` FUNCTION IS A HELPER FUNCTION WITHIN THE HDBSCAN ALGORITHM. ITS PURPOSE IS TO EXTRACT THE FINAL CLUSTERS FROM THE CONDENSED TREE REPRESENTATION.
    #     1. THE FUNCTION TAKES TWO PARAMETERS AS INPUT: THE CONDENSED TREE `CONDENSED_TREE` AND THE NUMBER OF SAMPLES `N_SAMPLES`.
    #     2. IT INITIALIZES AN ARRAY `LABELS` OF LENGTH `N_SAMPLES` TO STORE THE CLUSTER LABELS FOR EACH SAMPLE. INITIALLY, ALL ELEMENTS IN THE ARRAY ARE SET TO -1, INDICATING THAT NO CLUSTER ASSIGNMENT HAS BEEN MADE YET.
    #     3. IT ALSO INITIALIZES A VARIABLE `CLUSTER_ID` TO KEEP TRACK OF THE CURRENT CLUSTER ID. THE ID STARTS AT 0 AND INCREMENTS AS NEW CLUSTERS ARE DISCOVERED.
    #     4. THE FUNCTION ITERATES OVER THE EDGES OF THE CONDENSED TREE. THE EDGES REPRESENT CONNECTIONS BETWEEN SAMPLES, AND THEY ARE SORTED BASED ON THEIR EDGE LENGTHS IN ASCENDING ORDER.
    #     5. FOR EACH EDGE, REPRESENTED BY THE PAIR OF CONNECTED SAMPLES `CLUSTER_A` AND `CLUSTER_B`, THE FUNCTION EXAMINES THE CLUSTER LABELS OF THE TWO SAMPLES.
    #     6. IF BOTH `CLUSTER_A` AND `CLUSTER_B` HAVE UNASSIGNED LABELS (-1), IT MEANS THAT THEY ARE NOT PART OF ANY CLUSTER YET. IN THIS CASE, THE FUNCTION ASSIGNS THEM THE SAME `CLUSTER_ID` AND INCREMENTS THE `CLUSTER_ID` BY 1.
    #     7. IF ONE OF THE SAMPLES, SAY `CLUSTER_A`, HAS AN UNASSIGNED LABEL (-1), WHILE THE OTHER SAMPLE, `CLUSTER_B`, ALREADY HAS A LABEL ASSIGNED, THE FUNCTION ASSIGNS `CLUSTER_A` THE LABEL OF `CLUSTER_B`. THIS ENSURES THAT SAMPLES CONNECTED BY AN EDGE ARE PART OF THE SAME CLUSTER.
    #     8. IF BOTH `CLUSTER_A` AND `CLUSTER_B` HAVE ASSIGNED LABELS AND THE LABELS ARE DIFFERENT, IT MEANS THEY BELONG TO SEPARATE CLUSTERS. IN THIS CASE, THE FUNCTION MERGES THE CLUSTERS BY ASSIGNING THE MINIMUM LABEL TO ALL SAMPLES THAT HAVE EITHER LABEL. THIS ENSURES THAT ALL SAMPLES IN THE CONNECTED CLUSTERS ARE LABELED CONSISTENTLY.
    #     9. AFTER PROCESSING ALL EDGES, THE FUNCTION RETURNS THE `LABELS` ARRAY, WHICH NOW CONTAINS THE FINAL CLUSTER ASSIGNMENTS FOR EACH SAMPLE.
    #     10. PRIOR TO RETURNING THE `LABELS` ARRAY, THE FUNCTION APPLIES A POST-PROCESSING STEP USING THE `__POST_PROCESS_LABELS__` FUNCTION. THIS STEP RELABELS THE CLUSTERS SEQUENTIALLY STARTING FROM ZERO, ENSURING A SEQUENTIAL AND ZERO-BASED INDEXING OF THE CLUSTERS.
    # IN SUMMARY, THE `__EXTRACT_CLUSTERS__` FUNCTION EXTRACTS THE FINAL CLUSTERS FROM THE CONDENSED TREE REPRESENTATION BY EXAMINING THE EDGES OF THE TREE. IT ASSIGNS CLUSTER LABELS TO SAMPLES BASED ON THEIR CONNECTIONS IN THE TREE AND PERFORMS MERGING OPERATIONS TO ENSURE CONSISTENT LABELING ACROSS CLUSTERS. THE RESULTING CLUSTER ASSIGNMENTS ARE STORED IN THE `LABELS` ARRAY, WHICH IS RETURNED AS THE OUTPUT OF THE FUNCTION. THE POST-PROCESSING STEP FURTHER REFINES THE CLUSTER LABELS FOR BETTER INTERPRETATION AND ANALYSIS.
    def __EXTRACT_CLUSTERS__(CONDENSED_TREE, N_SAMPLES):
        """THE `__EXTRACT_CLUSTERS__` FUNCTION IS A HELPER FUNCTION WITHIN THE HDBSCAN ALGORITHM THAT EXTRACTS THE FINAL CLUSTERS FROM THE CONDENSED TREE REPRESENTATION.
            1. CONDENSED TREE: THE FUNCTION OPERATES ON THE CONDENSED TREE, WHICH REPRESENTS THE MERGED CLUSTERS AS EDGES BETWEEN SAMPLES.
            2. CLUSTER LABELS: THE FUNCTION ASSIGNS CLUSTER LABELS TO SAMPLES BASED ON THEIR CONNECTIONS IN THE CONDENSED TREE. IT EXAMINES THE EDGES OF THE TREE IN A SORTED ORDER.
            3. LABEL ASSIGNMENT: THE FUNCTION ASSIGNS LABELS TO SAMPLES BASED ON THEIR CURRENT LABELS AND THE LABELS OF THEIR CONNECTED SAMPLES. IT ENSURES THAT SAMPLES CONNECTED BY AN EDGE BELONG TO THE SAME CLUSTER.
            4. CLUSTER MERGING: IF TWO SAMPLES HAVE DIFFERENT LABELS BUT ARE CONNECTED BY AN EDGE, THE FUNCTION MERGES THE CLUSTERS BY ASSIGNING A COMMON LABEL TO ALL SAMPLES IN THE CONNECTED CLUSTERS.
            5. OUTPUT LABELS: THE FUNCTION RETURNS AN ARRAY OF CLUSTER LABELS, WHERE EACH LABEL INDICATES THE CLUSTER ASSIGNMENT OF THE CORRESPONDING SAMPLE.
            6. POST-PROCESSING: BEFORE RETURNING THE LABELS, THE FUNCTION APPLIES A POST-PROCESSING STEP TO REFINE THE CLUSTER LABELS. THIS STEP ENSURES SEQUENTIAL AND ZERO-BASED INDEXING OF THE CLUSTERS FOR BETTER INTERPRETATION AND ANALYSIS.
        IN SUMMARY, THE `__EXTRACT_CLUSTERS__` FUNCTION EXTRACTS THE FINAL CLUSTERS FROM THE CONDENSED TREE REPRESENTATION BY ASSIGNING LABELS TO SAMPLES BASED ON THEIR CONNECTIONS. IT MERGES CLUSTERS AS NEEDED AND PROVIDES AN ARRAY OF CLUSTER LABELS AS THE OUTPUT. THE POST-PROCESSING STEP FURTHER ENHANCES THE LABELLING FOR IMPROVED INTERPRETABILITY OF THE CLUSTERING RESULTS."""
        LABELS = np.full(N_SAMPLES, -1)  # INITIALIZE AN ARRAY OF LENGTH N_SAMPLES TO STORE THE CLUSTER LABELS FOR EACH SAMPLE. INITIALLY, ALL ELEMENTS IN THE ARRAY ARE SET TO -1, INDICATING THAT NO CLUSTER ASSIGNMENT HAS BEEN MADE YET.
        # INITIALIZE A VARIABLE TO KEEP TRACK OF THE CURRENT CLUSTER ID. THE ID STARTS AT 0 AND INCREMENTS AS NEW CLUSTERS ARE DISCOVERED.
        CLUSTER_ID = 0
        # ITERATE OVER THE EDGES OF THE CONDENSED TREE. THE EDGES REPRESENT CONNECTIONS BETWEEN SAMPLES, AND THEY ARE SORTED BASED ON THEIR EDGE LENGTHS IN ASCENDING ORDER.
        for EDGE, _ in sorted(CONDENSED_TREE.items(), key=lambda x: x[1]):
            # EXTRACT THE TWO SAMPLES CONNECTED BY THE EDGE.
            CLUSTER_A, CLUSTER_B = EDGE
            # IF BOTH SAMPLES HAVE UNASSIGNED LABELS, IT MEANS THAT THEY ARE NOT PART OF ANY CLUSTER YET. IN THIS CASE, ASSIGN THEM THE SAME CLUSTER ID AND INCREMENT THE CLUSTER ID BY 1.
            if LABELS[CLUSTER_A] == -1 and LABELS[CLUSTER_B] == -1:
                # ASSIGN THE CURRENT CLUSTER ID TO THE FIRST SAMPLE.
                LABELS[CLUSTER_A] = CLUSTER_ID
                # ASSIGN THE CURRENT CLUSTER ID TO THE SECOND SAMPLE.
                LABELS[CLUSTER_B] = CLUSTER_ID
                CLUSTER_ID += 1  # INCREMENT THE CLUSTER ID BY 1.
            # IF ONLY THE FIRST SAMPLE HAS AN UNASSIGNED LABEL, IT MEANS THAT IT IS NOT PART OF ANY CLUSTER YET. IN THIS CASE, ASSIGN IT THE SAME CLUSTER ID AS THE SECOND SAMPLE.
            elif LABELS[CLUSTER_A] == -1:
                # ASSIGN THE LABEL OF THE SECOND SAMPLE TO THE FIRST SAMPLE.
                LABELS[CLUSTER_A] = LABELS[CLUSTER_B]
            # IF ONLY THE SECOND SAMPLE HAS AN UNASSIGNED LABEL, IT MEANS THAT IT IS NOT PART OF ANY CLUSTER YET. IN THIS CASE, ASSIGN IT THE SAME CLUSTER ID AS THE FIRST SAMPLE.
            elif LABELS[CLUSTER_B] == -1:
                # ASSIGN THE LABEL OF THE FIRST SAMPLE TO THE SECOND SAMPLE.
                LABELS[CLUSTER_B] = LABELS[CLUSTER_A]
            # IF BOTH SAMPLES HAVE ASSIGNED LABELS, IT MEANS THAT THEY ARE PART OF DIFFERENT CLUSTERS. IN THIS CASE, MERGE THE TWO CLUSTERS BY ASSIGNING A COMMON LABEL TO ALL SAMPLES IN THE CONNECTED CLUSTERS.
            elif LABELS[CLUSTER_A] != LABELS[CLUSTER_B]:
                # DETERMINE THE LABEL OF THE CLUSTER TO WHICH THE SAMPLES WILL BE MERGED. THE MERGE LABEL IS THE SMALLER OF THE TWO LABELS.
                MERGE_LABEL = min(LABELS[CLUSTER_A], LABELS[CLUSTER_B])
                # ASSIGN THE MERGE LABEL TO ALL SAMPLES IN THE CONNECTED CLUSTERS.
                LABELS[np.logical_or(
                    LABELS == LABELS[CLUSTER_A], LABELS == LABELS[CLUSTER_B])] = MERGE_LABEL
        # RETURN THE CLUSTER LABELS AFTER APPLYING THE POST-PROCESSING STEP.
        return __POST_PROCESS_LABELS__(LABELS)

    # THE `__POST_PROCESS_LABELS__` FUNCTION IS A HELPER FUNCTION WITHIN THE HDBSCAN ALGORITHM. ITS PURPOSE IS TO PERFORM A POST-PROCESSING STEP ON THE CLUSTER LABELS OBTAINED FROM THE CONDENSED TREE.
    #     1. THE FUNCTION TAKES THE ARRAY OF CLUSTER LABELS `LABELS` AS INPUT.
    #     2. IT BEGINS BY USING THE `NP.UNIQUE` FUNCTION TO IDENTIFY THE UNIQUE CLUSTER LABELS PRESENT IN THE `LABELS` ARRAY. THE UNIQUE LABELS REPRESENT THE DISTINCT CLUSTERS IDENTIFIED IN THE DATASET.
    #     3. IT INITIALIZES AN ARRAY `NEW_LABELS` OF THE SAME SIZE AS `LABELS`, INITIALLY FILLED WITH -1. THIS ARRAY WILL STORE THE NEW AND MODIFIED LABELS AFTER THE POST-PROCESSING STEP.
    #     4. THE FUNCTION ITERATES OVER THE UNIQUE CLUSTER LABELS OBTAINED IN STEP 2, ALONG WITH THEIR CORRESPONDING INDICES.
    #     5. FOR EACH UNIQUE LABEL, THE FUNCTION ASSIGNS A NEW LABEL INDEX TO ALL SAMPLES IN `LABELS` THAT HAVE THE SAME LABEL. THIS RELABELING IS PERFORMED TO ENSURE SEQUENTIAL AND ZERO-BASED INDEXING OF THE CLUSTERS.
    #     6. AFTER PROCESSING ALL UNIQUE LABELS, THE `NEW_LABELS` ARRAY CONTAINS THE UPDATED CLUSTER LABELS, WITH CLUSTERS RELABELED SEQUENTIALLY STARTING FROM ZERO.
    #     7. FINALLY, THE `NEW_LABELS` ARRAY IS RETURNED AS THE OUTPUT OF THE `__POST_PROCESS_LABELS__` FUNCTION.
    # IN SUMMARY, THE `__POST_PROCESS_LABELS__` FUNCTION PERFORMS A POST-PROCESSING STEP ON THE CLUSTER LABELS OBTAINED FROM THE CONDENSED TREE. IT RELABELS THE CLUSTERS SEQUENTIALLY STARTING FROM ZERO TO PROVIDE A CONSISTENT AND EASILY INTERPRETABLE LABELING SCHEME. THE RESULTING ARRAY OF RELABELED CLUSTER LABELS IS RETURNED AS THE OUTPUT OF THE FUNCTION. THIS POST-PROCESSING STEP ENHANCES THE CLARITY AND USABILITY OF THE CLUSTERING RESULTS.
    def __POST_PROCESS_LABELS__(LABELS):
        # IDENTIFY THE UNIQUE CLUSTER LABELS PRESENT IN THE `LABELS` ARRAY.
        UNIQUE_LABELS = np.unique(LABELS)
        # INITIALIZE AN ARRAY OF THE SAME SIZE AS `LABELS`, INITIALLY FILLED WITH -1.
        NEW_LABELS = -1 * np.ones_like(LABELS)
        # ITERATE OVER THE UNIQUE CLUSTER LABELS ALONG WITH THEIR CORRESPONDING INDICES.
        for IDX, LABEL in enumerate(UNIQUE_LABELS):
            # ASSIGN A NEW LABEL INDEX TO ALL SAMPLES IN `LABELS` THAT HAVE THE SAME LABEL.
            NEW_LABELS[LABELS == LABEL] = IDX
        return NEW_LABELS  # RETURN THE UPDATED CLUSTER LABELS.

    # ASSIGN THE NUMBER OF SAMPLES IN `X` TO THE VARIABLE `N_SAMPLES`.
    N_SAMPLES = X.shape[0]
    # COMPUTE THE CORE DISTANCES FOR ALL SAMPLES IN `X`.
    CORE_DISTANCES = __COMPUTE_CORE_DISTANCES__(X)
    # COMPUTE THE NEIGHBOURS FOR ALL SAMPLES IN `X`.
    NEIGHBOURS = __COMPUTE_NEIGHBOURS__(X, CORE_DISTANCES)
    # CONSTRUCT THE CONDENSED TREE FOR THE SAMPLES IN `X`.
    CONDENSED_TREE = __CONDENSE_TREE__(X, NEIGHBOURS, CORE_DISTANCES)
    # EXTRACT THE CLUSTERS FROM THE CONDENSED TREE.
    LABELS = __EXTRACT_CLUSTERS__(CONDENSED_TREE, N_SAMPLES)
    return LABELS  # RETURN THE CLUSTER LABELS.

# THE `PAIRWISE_DISTANCES` FUNCTION CALCULATES THE PAIRWISE DISTANCES BETWEEN A SET OF SAMPLES REPRESENTED BY A MATRIX `X`.
#     1. THE FUNCTION TAKES A SINGLE PARAMETER `X`, WHICH IS EXPECTED TO BE A NUMPY ARRAY REPRESENTING THE SAMPLES. EACH ROW IN `X` CORRESPONDS TO A SINGLE SAMPLE, AND THE COLUMNS REPRESENT DIFFERENT FEATURES OR DIMENSIONS OF THE SAMPLES.
#     2. `N_SAMPLES = X.SHAPE[0]` ASSIGNS THE NUMBER OF SAMPLES IN `X` TO THE VARIABLE `N_SAMPLES`. THIS VALUE IS USED TO DETERMINE THE SIZE OF THE RESULTING DISTANCE MATRIX.
#     3. `DISTANCES = NP.ZEROS((N_SAMPLES, N_SAMPLES))` CREATES AN EMPTY SQUARE MATRIX OF SIZE `N_SAMPLES` BY `N_SAMPLES` USING NUMPY'S `ZEROS` FUNCTION. THIS MATRIX WILL STORE THE PAIRWISE DISTANCES BETWEEN THE SAMPLES.
#     4. THE FUNCTION ENTERS A NESTED LOOP WITH THE OUTER LOOP ITERATING OVER THE RANGE OF `N_SAMPLES`. THE VARIABLE `I` REPRESENTS THE CURRENT ROW INDEX.
#     5. THE INNER LOOP ITERATES OVER THE RANGE FROM `I + 1` TO `N_SAMPLES`. THE VARIABLE `J` REPRESENTS THE CURRENT COLUMN INDEX.
#     6. INSIDE THE NESTED LOOP, `DISTANCES[I, J] = DISTANCES[J, I] = NP.LINALG.NORM(X[I] - X[J])` CALCULATES THE EUCLIDEAN DISTANCE BETWEEN THE `I`-TH AND `J`-TH SAMPLES. `NP.LINALG.NORM` COMPUTES THE NORM OF THE VECTOR DIFFERENCE `X[I] - X[J]`, WHICH REPRESENTS THE DISTANCE BETWEEN THE TWO SAMPLES. THE CALCULATED DISTANCE IS THEN ASSIGNED TO BOTH `DISTANCES[I, J]` AND `DISTANCES[J, I]` TO ENSURE THAT THE DISTANCE MATRIX IS SYMMETRIC.
#     7. AFTER THE NESTED LOOPS HAVE ITERATED OVER ALL PAIRS OF SAMPLES, THE FUNCTION RETURNS THE RESULTING DISTANCE MATRIX `DISTANCES`.
# IN SUMMARY, THE `PAIRWISE_DISTANCES` FUNCTION CALCULATES THE PAIRWISE DISTANCES BETWEEN SAMPLES BY COMPUTING THE EUCLIDEAN DISTANCE BETWEEN EACH PAIR OF SAMPLES AND STORING THE DISTANCES IN A SYMMETRIC MATRIX. THIS FUNCTION CAN BE USEFUL IN VARIOUS APPLICATIONS SUCH AS CLUSTERING, DIMENSIONALITY REDUCTION, OR SIMILARITY ANALYSIS.


def PAIRWISE_DISTANCES(X):
    """THE `PAIRWISE_DISTANCES` FUNCTION IS A PYTHON IMPLEMENTATION THAT CALCULATES THE PAIRWISE DISTANCES BETWEEN SAMPLES IN A GIVEN DATASET. IT UTILIZES THE NUMPY LIBRARY FOR EFFICIENT MATHEMATICAL OPERATIONS.
    THE FUNCTION TAKES A MATRIX `X` AS INPUT, WHERE EACH ROW REPRESENTS A SAMPLE AND THE COLUMNS CORRESPOND TO DIFFERENT FEATURES OR DIMENSIONS OF THE SAMPLES. IT INITIALIZES AN EMPTY DISTANCE MATRIX OF SIZE `N_SAMPLES` BY `N_SAMPLES`, WHERE `N_SAMPLES` IS THE NUMBER OF SAMPLES IN THE INPUT MATRIX.
    USING NESTED LOOPS, THE FUNCTION ITERATES OVER EACH PAIR OF SAMPLES, EXCLUDING SELF-PAIRS AND REDUNDANT COMPUTATIONS DUE TO SYMMETRY. FOR EACH PAIR, IT CALCULATES THE EUCLIDEAN DISTANCE BETWEEN THE SAMPLES USING THE `NP.LINALG.NORM` FUNCTION, WHICH CALCULATES THE NORM OF THE VECTOR DIFFERENCE. THE RESULTING DISTANCE IS STORED IN BOTH THE CORRESPONDING CELLS OF THE DISTANCE MATRIX TO ENSURE SYMMETRY.
    ONCE ALL PAIRWISE DISTANCES HAVE BEEN COMPUTED, THE FUNCTION RETURNS THE DISTANCE MATRIX, WHICH PROVIDES A COMPREHENSIVE REPRESENTATION OF THE DISTANCES BETWEEN ALL SAMPLES IN THE DATASET.
    THIS FUNCTION CAN BE VALUABLE IN VARIOUS APPLICATIONS SUCH AS CLUSTERING ALGORITHMS, WHERE KNOWING THE DISTANCES BETWEEN SAMPLES IS CRUCIAL FOR GROUPING SIMILAR SAMPLES TOGETHER. ADDITIONALLY, IT CAN BE USED IN DIMENSIONALITY REDUCTION TECHNIQUES OR SIMILARITY ANALYSIS, WHERE THE DISTANCES BETWEEN SAMPLES HELP QUANTIFY THE RELATIONSHIPS OR SIMILARITIES BETWEEN THEM."""
    N_SAMPLES = X.shape[0]  # ASSIGN THE NUMBER OF SAMPLES IN `X` TO THE VARIABLE `N_SAMPLES`.
    # INITIALIZE AN EMPTY DISTANCE MATRIX OF SIZE `N_SAMPLES` BY `N_SAMPLES`.
    DISTANCES = np.zeros((N_SAMPLES, N_SAMPLES))
    for i in range(N_SAMPLES):  # ITERATE OVER THE SAMPLES IN `X`.
        # ITERATE OVER THE SAMPLES IN `X` STARTING FROM THE CURRENT SAMPLE.
        for j in range(i + 1, N_SAMPLES):
            # CALCULATE THE EUCLIDEAN DISTANCE BETWEEN THE CURRENT SAMPLE AND THE `J`-TH SAMPLE.
            DISTANCES[i, j] = DISTANCES[j, i] = np.linalg.norm(X[i] - X[j])
    return DISTANCES  # RETURN THE DISTANCE MATRIX.
