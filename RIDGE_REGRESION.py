import numpy as np

# RIDGE_REGRESSION: IMPLEMENTS THE RIDGE REGRESSION MODEL. IT'S A LINEAR REGRESSION MODEL WHERE THE LOSS FUNCTION IS MODIFIED TO MINIMIZE THE COMPLEXITY OF THE MODEL. THIS IS DONE BY ADDING A PENALTY TERM TO THE LOSS FUNCTION. THE COEFFICIENTS ARE ESTIMATED USING THE ORDINARY LEAST SQUARES METHOD. THE RIDGE REGRESSION MODEL IS PARTICULARLY USEFUL TO ALLEVIATE THE PROBLEM OF MULTICOLLINEARITY IN LINEAR REGRESSION, WHICH COMMONLY OCCURS IN MODELS WITH LARGE NUMBERS OF PARAMETERS. IN RIDGE REGRESSION, THE COST FUNCTION IS ALTERED BY ADDING A PENALTY EQUIVALENT TO SQUARE OF THE MAGNITUDE OF THE COEFFICIENTS. MEANING, IT'S A LINEAR LEAST SQUARES MODEL WITH L2 REGULARIZATION.
class RIDGE_REGRESSION:
    # INITIALIZES THE RIDGE REGRESSION MODEL.
    def __init__(self, LEARNING_RATE=0.01, ITERATIONS=1000, L2_PENALITY=0.01):
        # LEARNING_RATE: IT'S THE HYPERPARAMETER THAT CORRESPONDS TO THE LEARNING RATE. IT CONTROLS HOW MUCH TO CHANGE THE MODEL IN RESPONSE TO THE ESTIMATED ERROR EACH TIME THE MODEL WEIGHTS ARE UPDATED.
        self.LEARNING_RATE = LEARNING_RATE
        # ITERATIONS: IT'S THE HYPERPARAMETER THAT CORRESPONDS TO THE NUMBER OF ITERATIONS. IT CONTROLS THE NUMBER OF TIMES TO REPEAT THE PROCESS OF LEARNING THE WEIGHTS.
        self.ITERATIONS = ITERATIONS
        # L2_PENALITY: IT'S THE HYPERPARAMETER THAT CORRESPONDS TO THE L2 PENALTY. IT CONTROLS THE STRENGTH OF THE PENALTY TERM.
        self.L2_PENALITY = L2_PENALITY
        # WEIGHTS: IT'S THE PARAMETER THAT CORRESPONDS TO THE WEIGHTS OF THE LINEAR REGRESSION MODEL.
        self.WEIGHTS = None
        # BIAS: IT'S THE PARAMETER THAT CORRESPONDS TO THE BIAS OF THE LINEAR REGRESSION MODEL.
        self.BIAS = 0

    # FIT: IMPLEMENTS THE FIT METHOD OF THE RIDGE REGRESSION MODEL.
    def FIT(self, X, Y):
        # CALCULATE THE WEIGHTS OF THE LINEAR REGRESSION MODEL.
        self.WEIGHTS = np.zeros(X.shape[1])
        # ITERATE THROUGH THE NUMBER OF ITERATIONS.
        for _ in range(self.ITERATIONS):
            # CALCULATE THE PREDICTIONS OF THE LINEAR REGRESSION MODEL.
            Y_PRED = self.TRANSFORM(X)
            # CALCULATE THE DERIVATIVE OF THE WEIGHTS.
            DERIVATIVE_WEIGHTS = (-(2 * (X.T).dot(Y - Y_PRED)) +
                                  (2 * self.L2_PENALITY * self.WEIGHTS)) / X.shape[0]
            # CALCULATE THE DERIVATIVE OF THE BIAS.
            DERIVATIVE_BIAS = -2 * np.sum(Y - Y_PRED) / X.shape[0]
            # UPDATE THE WEIGHTS.
            self.WEIGHTS = self.WEIGHTS - self.LEARNING_RATE * DERIVATIVE_WEIGHTS
            # UPDATE THE BIAS.
            self.BIAS = self.BIAS - self.LEARNING_RATE * DERIVATIVE_BIAS

    # TRANSFORM(): PREDICTS THE LABELS OF THE TRAINING DATA.
    def TRANSFORM(self, X):
        # RETURNS THE PREDICTIONS OF THE LINEAR REGRESSION MODEL.
        return X.dot(self.WEIGHTS) + self.BIAS