import numpy as np

# POLYNOMIAL_REGRESSION: IMPLEMENTS THE POLYNOMIAL REGRESSION MODEL. WHICH IS A FORM OF REGRESSION ANALYSIS IN WHICH THE RELATIONSHIP BETWEEN THE INDEPENDENT VARIABLE X AND THE DEPENDENT VARIABLE Y IS MODELLED AS AN NTH DEGREE POLYNOMIAL IN X.
class POLYNOMIAL_REGRESSION:
    """IMPLEMENTS THE POLYNOMIAL REGRESSION MODEL. WHICH IS A FORM OF REGRESSION ANALYSIS IN WHICH THE RELATIONSHIP BETWEEN THE INDEPENDENT VARIABLE X AND THE DEPENDENT VARIABLE Y IS MODELLED AS AN NTH DEGREE POLYNOMIAL IN X.

    ATTRIBUTES
    ----------
    LEARNING_RATE: IT'S THE HYPERPARAMETER THAT CORRESPONDS TO THE LEARNING RATE OF THE ALGORITHM.
    BATCH_SIZE: IT'S THE HYPERPARAMETER THAT CORRESPONDS TO THE NUMBER OF SAMPLES TO BE USED IN EACH ITERATION.
    EPOCHS: IT'S THE HYPERPARAMETER THAT CORRESPONDS TO THE NUMBER OF ITERATIONS THAT THE ALGORITHM PASS THROUGH THE TRAINING DATA.
    WEIGHTS: IT'S THE PARAMETER THAT CORRESPONDS TO THE WEIGHTS OF THE POLYNOMIAL REGRESSION MODEL.
    BIAS: IT'S THE PARAMETER THAT CORRESPONDS TO THE BIAS OF THE POLYNOMIAL REGRESSION MODEL.

    METHODS
    -------
    FIT(X, Y, DEGREES): TRAINS THE POLYNOMIAL REGRESSION MODEL.
    PREDICT(X, DEGREES): PREDICTS THE TARGET VALUES.
    [PRIVATE & STATIC] __LOSS_FUNCTION(TRUE_TARGET_VALUE, PREDICTION): RETURNS THE LOSS VALUE.
    [PRIVATE] __GRADIENT(X, Y, PREDICTION): RETURNS THE GRADIENT OF THE LOSS FUNCTION W.R.T. THE PARAMETERS: WEIGHTS AND BIAS.
    [PRIVATE] __X_PREDICT__(X, DEGREES): ADDS FEATURES TO THE INPUT X (FEATURES ARE POWERS OF X).
    [STATIC] MEAN_SQUARED_ERROR(Y_TRUE, Y_PREDICTED): RETURNS THE MEAN SQUARED ERROR.
    [STATIC] SQUARED_ERROR(Y_TRUE, Y_PREDICTED): RETURNS THE SQUARED ERROR.
    """
    # INITIALIZES THE POLYNOMIAL REGRESSION MODEL
    def __init__(self, LEARNING_RATE=0.01, BATCH_SIZE=32, EPOCHS=1000):
        """INITIALIZES THE POLYNOMIAL REGRESSION MODEL.
        
        PARAMETERS
        ----------
        LEARNING_RATE: FLOAT, OPTIONAL (DEFAULT=0.01)
            HYPERPARAMETER THAT CONTROLS THE STEP SIZE AT EACH ITERATION WHILE MOVING TOWARDS A MINIMUM OF A LOSS FUNCTION.
        BATCH_SIZE: INT, OPTIONAL (DEFAULT=32)
            HYPERPARAMETER THAT CONTROLS THE NUMBER OF SAMPLES TO BE USED IN EACH ITERATION.
        EPOCHS: INT, OPTIONAL (DEFAULT=1000)
            IT'S THE HYPERPARAMETER THAT CORRESPONDS TO THE NUMBER OF ITERATIONS THAT THE ALGORITHM PASS THROUGH THE TRAINING DATA.

        ATTRIBUTES
        ----------
        LEARNING_RATE: FLOAT
            IT'S THE HYPERPARAMETER THAT CORRESPONDS TO THE LEARNING RATE OF THE ALGORITHM.
        BATCH_SIZE: INT
            IT'S THE HYPERPARAMETER THAT CORRESPONDS TO THE NUMBER OF SAMPLES TO BE USED IN EACH ITERATION.
        EPOCHS: INT
            IT'S THE HYPERPARAMETER THAT CORRESPONDS TO THE NUMBER OF ITERATIONS THAT THE ALGORITHM PASS THROUGH THE TRAINING DATA.
        WEIGHTS: NUMPY ARRAY
            IT'S THE PARAMETER THAT CORRESPONDS TO THE WEIGHTS OF THE POLYNOMIAL REGRESSION MODEL.
        BIAS: FLOAT
            IT'S THE PARAMETER THAT CORRESPONDS TO THE BIAS OF THE POLYNOMIAL REGRESSION MODEL.
        """
        # LEARNING RATE: HYPERPARAMETER THAT CONTROLS THE STEP SIZE AT EACH ITERATION WHILE MOVING TOWARDS A MINIMUM OF A LOSS FUNCTION.
        self.LEARNING_RATE = LEARNING_RATE
        # BATCH SIZE: HYPERPARAMETER THAT CONTROLS THE NUMBER OF SAMPLES TO BE USED IN EACH ITERATION.
        self.BATCH_SIZE = BATCH_SIZE
        # NUMBER OF ITERATIONS: IT'S THE HYPERPARAMETER THAT CORRESPONDS TO THE NUMBER OF ITERATIONS THAT THE ALGORITHM PASS THROUGH THE TRAINING DATA.
        self.EPOCHS = EPOCHS
        # WEIGHTS: IT'S THE PARAMETER THAT CORRESPONDS TO THE WEIGHTS OF THE POLYNOMIAL REGRESSION MODEL.
        self.WEIGHTS = None
        # BIAS: IT'S THE PARAMETER THAT CORRESPONDS TO THE BIAS OF THE POLYNOMIAL REGRESSION MODEL.
        self.BIAS = None

    # FIT(): TRAINS THE POLYNOMIAL REGRESSION MODEL
    def FIT(self, X, Y, DEGREES):
        """TRAIN THE POLYNOMIAL REGRESSION MODEL.

        PARAMETERS
        ----------
        X: NUMPY ARRAY
            IT'S THE INPUT OF THE POLYNOMIAL REGRESSION MODEL.
        Y: NUMPY ARRAY
            IT'S THE TARGET OF THE POLYNOMIAL REGRESSION MODEL.
        DEGREES: INT
            IT'S THE DEGREE OF THE POLYNOMIAL REGRESSION MODEL.

        RETURNS
        -------
        NONE
        """
        # ADDS FEATURES TO THE INPUT X (FEATURES ARE POWERS OF X)
        _X = self.__X_PREDICT__(X, DEGREES)
        # NUMBER OF TRAINING EXAMPLES AND NUMBER OF FEATURES
        NUMBER_OF_SAMPLES, NUMBER_OF_FEATURES = X.shape
        # INITIALIZE WEIGHTS TO ZERO
        self.WEIGHTS = np.zeros((NUMBER_OF_FEATURES, 1))
        self.BIAS = 0  # INITIALIZE BIAS TO ZERO
        # RESHAPES Y TO (NUMBER_OF_SAMPLES, 1)
        Y = Y.reshape(NUMBER_OF_SAMPLES, 1)
        LOSS = []  # LIST TO STORE LOSS
        for _ in range(self.EPOCHS):  # FOR EACH EPOCH
            # FOR EACH BATCH
            for EXAMPLE_INDEX in range((NUMBER_OF_SAMPLES - 1) // self.BATCH_SIZE + 1):
                START_INDEX = EXAMPLE_INDEX * self.BATCH_SIZE  # START INDEX OF THE BATCH
                END_INDEX = START_INDEX + self.BATCH_SIZE  # END INDEX OF THE BATCH
                X_BATCH = _X[START_INDEX:END_INDEX]  # X_BATCH: BATCH OF INPUTS
                # Y_BATCH: BATCH OF TARGET VALUES
                Y_BATCH = Y[START_INDEX:END_INDEX]
                # PREDICTION: PREDICTED TARGET VALUES
                PREDICTION = np.dot(X_BATCH, self.WEIGHTS) + self.BIAS
                # DERIVATIVE OF THE LOSS FUNCTION W.R.T. THE PARAMETERS: WEIGHTS AND BIAS
                DERIVATIVE_WEIGHTS, DERIVATIVE_BIAS = self.__GRADIENTS__(
                    X_BATCH, Y_BATCH, PREDICTION)
                self.WEIGHTS -= self.LEARNING_RATE * DERIVATIVE_WEIGHTS  # UPDATES THE WEIGHTS
                self.BIAS -= self.LEARNING_RATE * DERIVATIVE_BIAS  # UPDATES THE BIAS
            # CALCULATES THE LOSS AND APPENDS IT TO THE LIST
            LOSS.append(self.__LOSS_FUNCTION__(
                Y, np.dot(_X, self.WEIGHTS) + self.BIAS))

    # PREDICT(): PREDICTS THE TARGET VALUES
    def PREDICT(self, X, DEGREES):
        """PREDICTS THE TARGET VALUES.

        PARAMETERS
        ----------
        X: NUMPY ARRAY
            IT'S THE INPUT OF THE POLYNOMIAL REGRESSION MODEL.
        DEGREES: INT
            IT'S THE DEGREE OF THE POLYNOMIAL REGRESSION MODEL.

        RETURNS
        -------
        NUMPY ARRAY
            IT'S THE PREDICTED TARGET VALUES.
        
        EXCEPTIONS
        ----------
        ASSERTION ERROR: IF FIT() IS NOT RUN BEFORE PREDICT()
        """
        assert self.WEIGHTS is not None and self.BIAS is not None, "RUN FIT() FIRST"  # ASSERTION TO CHECK IF FIT() IS RUN BEFORE PREDICT()
        # ADDS FEATURES TO THE INPUT X (FEATURES ARE POWERS OF X)
        _X = self.__X_PREDICT__(X, DEGREES)
        # PREDICTS THE TARGET VALUES
        return np.dot(_X, self.WEIGHTS) + self.BIAS

    # LOSS FUNCTION [PRIVATE & STATIC]: CALCULATES THE LOSS FUNCTION: MEAN SQUARED ERROR
    @staticmethod
    def __LOSS_FUNCTION__(TRUE_TARGET_VALUE, PREDICTION):
        """[PRIVATE & STATIC] CALCULATES THE LOSS FUNCTION: MEAN SQUARED ERROR.

        PARAMETERS
        ----------
        TRUE_TARGET_VALUE: NUMPY ARRAY
            IT'S THE TRUE TARGET VALUES.
        PREDICTION: NUMPY ARRAY
            IT'S THE PREDICTED TARGET VALUES.
        
        RETURNS
        -------
        FLOAT
            IT'S THE LOSS FUNCTION: MEAN SQUARED ERROR.
        """
        # RETURNS THE LOSS FUNCTION
        return POLYNOMIAL_REGRESSION.MEAN_SQUARED_ERROR(TRUE_TARGET_VALUE, PREDICTION)

    # GRADIENTS [PRIVATE FUNCTION]: CALCULATES THE GRADIENTS OF THE LOSS FUNCTION W.R.T. THE PARAMETERS: WEIGHTS AND BIAS
    def __GRADIENTS__(self, X, Y, PREDICTION):
        """[PRIVATE FUNCTION] CALCULATES THE GRADIENTS OF THE LOSS FUNCTION W.R.T. THE PARAMETERS: WEIGHTS AND BIAS.

        PARAMETERS
        ----------
        X: NUMPY ARRAY
            IT'S THE INPUT OF THE POLYNOMIAL REGRESSION MODEL.
        Y: NUMPY ARRAY
            IT'S THE TARGET OF THE POLYNOMIAL REGRESSION MODEL.
        PREDICTION: NUMPY ARRAY
            IT'S THE PREDICTED TARGET VALUES.
        
        RETURNS
        -------
        NUMPY ARRAY, FLOAT
            IT'S THE GRADIENTS OF THE LOSS FUNCTION W.R.T. THE PARAMETERS: WEIGHTS AND BIAS.
        """
        NUMBER_OF_SAMPLES = X.shape[0]  # NUMBER OF TRAINING EXAMPLES
        # DERIVATIVE OF THE LOSS FUNCTION W.R.T. THE WEIGHTS
        DERIVATIVE_WEIGHTS = (1 / NUMBER_OF_SAMPLES) * \
            np.dot(X.T, (PREDICTION - Y))
        # DERIVATIVE OF THE LOSS FUNCTION W.R.T. THE BIAS
        DERIVATIVE_BIAS = (1 / NUMBER_OF_SAMPLES) * np.sum(PREDICTION - Y)
        # RETURNS THE GRADIENTS OF THE LOSS FUNCTION W.R.T. THE PARAMETERS: WEIGHTS AND BIAS
        return DERIVATIVE_WEIGHTS, DERIVATIVE_BIAS

    # X_PREDICT [PRIVATE FUNCTION]: ADDS FEATURES TO THE INPUT X (FEATURES ARE POWERS OF X)
    def __X_PREDICT__(self, X, DEGREES):
        """[PRIVATE FUNCTION] ADDS FEATURES TO THE INPUT X (FEATURES ARE POWERS OF X).

        PARAMETERS
        ----------
        X: NUMPY ARRAY
            IT'S THE INPUT OF THE POLYNOMIAL REGRESSION MODEL.
        DEGREES: INT
            IT'S THE DEGREE OF THE POLYNOMIAL REGRESSION MODEL.

        RETURNS
        -------
        NUMPY ARRAY
            IT'S THE INPUT OF THE POLYNOMIAL REGRESSION MODEL WITH ADDED FEATURES.
        """
        T = X.copy()  # COPY OF X
        for DEGREE in DEGREES:  # FOR EACH DEGREE IN DEGREES
            X = np.append(X, T ** DEGREE, axis=1)  # ADD X^(DEGREE) TO X
        return X  # RETURNS X
    
    # SQUARED_ERROR [STATIC]: RETURNS SQUARED ERROR
    @staticmethod
    def MEAN_SQUARED_ERROR(ACTUAL, PREDICTED):
        """[STATIC] RETURN MEAN SQUARED ERROR.

        PARAMETERS:
        -----------
        ACTUAL: NUMPY ARRAY
            ACTUAL VALUES.
        PREDICTED: NUMPY ARRAY
            PREDICTED VALUES.

        RETURNS:
        --------
        MEAN_SQUARED_ERROR: NUMPY ARRAY
            MEAN SQUARED ERROR.
        """
        return np.mean(POLYNOMIAL_REGRESSION.SQUARED_ERROR(ACTUAL, PREDICTED))  # RETURN MEAN SQUARED ERROR: np.mean((ACTUAL - PREDICTED) ** 2)
    
    # SQUARED_ERROR [STATIC]: RETURNS SQUARED ERROR
    @staticmethod
    def SQUARED_ERROR(ACTUAL, PREDICTED):
        """[STATIC] RETURN SQUARED ERROR.

        PARAMETERS:
        -----------
        ACTUAL: NUMPY ARRAY
            ACTUAL VALUES.
        PREDICTED: NUMPY ARRAY
            PREDICTED VALUES.

        RETURNS:
        --------
        SQUARED_ERROR: NUMPY ARRAY
            SQUARED ERROR.
        """
        return (ACTUAL - PREDICTED) ** 2  # RETURN SQUARED ERROR: (ACTUAL - PREDICTED) ** 2