import numpy as np
from numpy.linalg import multi_dot
from numpy.linalg import inv
from numpy.linalg import det

# QUADRATIC_DISCRIMINANT_ANALYSIS: IMPLEMENTATION OF QUADRATIC DISCRIMINANT ANALYSIS. QUADRATIC DISCRIMINANT ANALYSIS (QDA) IS A METHOD USED WHEN YOU HAVE A SET OF PREDICTOR VARIABLES AND YOUâ€™D LIKE TO CLASSIFY A RESPONSE VARIABLE INTO TWO OR MORE CLASSES. IT IS CONSIDERED TO BE THE NON-LINEAR EQUIVALENT TO LINEAR DISCRIMINANT ANALYSIS. QDA ASSUMES THAT EACH CLASS FOLLOWS A GAUSSIAN DISTRIBUTION. THE CLASS-SPECIFIC PRIOR IS SIMPLY THE PROPORTION OF DATA POINTS THAT BELONG TO THE CLASS. THE CLASS-SPECIFIC MEAN VECTOR IS THE AVERAGE OF THE INPUT VARIABLES THAT BELONG TO THE CLASS.
class QUADRATIC_DISCRIMINANT_ANALYSIS:
    # INITIALIZES THE QUADRATIC DISCRIMINANT ANALYSIS MODEL.
    def __init__(self):
        # ESTIMATES: THE ESTIMATES OF THE LINEAR DISCRIMINANT ANALYSIS MODEL; MEANING THE ESTIMATES OF THE CLASSES; EACH ESTIMATE IS A TUPLE OF THE FORM (CLASS, PROBABILITY, MEAN, VARIANCE)
        self.ESTIMATES = None

    # FIT: FITS THE QUADRATIC DISCRIMINANT ANALYSIS MODEL.
    def FIT(self, X, Y):
        CLASSES = list(np.unique(Y)) # GET THE UNIQUE CLASSES
        ESTIMATES = [] # INITIALIZE THE ESTIMATES LIST
        for _C in CLASSES: # ITERATE THROUGH THE CLASSES
            ESTIMATE = [] # INITIALIZE THE ESTIMATE LIST
            ESTIMATE.append(_C) # ADD THE CLASS TO THE ESTIMATE LIST
            IDX_ROWS = np.where(np.isin(Y,_C)) # GET THE INDICES OF THE ROWS WHERE THE CLASS IS PRESENT
            X_SUBSET = X[IDX_ROWS] # GET THE SUBSET OF THE DATA WHERE THE CLASS IS PRESENT
            PI = float(len(X_SUBSET))/float(len(X)) # COMPUTE THE PROBABILITY OF THE CLASS
            ESTIMATE.append(PI) # ADD THE PROBABILITY OF THE CLASS TO THE ESTIMATE LIST
            MEAN = (np.sum(X_SUBSET,axis=0) / float(len(X_SUBSET))).reshape(-1,1) # COMPUTE THE MEAN OF THE CLASS
            ESTIMATE.append(MEAN) # ADD THE MEAN OF THE CLASS TO THE ESTIMATE LIST
            VARIANCE = (1./(len(X_SUBSET) - len(CLASSES))) * (sum([(ROW.reshape(-1,1) - MEAN).dot((ROW.reshape(-1,1) - MEAN).T) for ROW in X_SUBSET])) # COMPUTE THE VARIANCE OF THE CLASS
            ESTIMATE.append(VARIANCE) # ADD THE VARIANCE OF THE CLASS TO THE ESTIMATE LIST
            ESTIMATES.append(tuple(ESTIMATE)) # ADD THE ESTIMATE TO THE ESTIMATES LIST
            VARIANCE = sum([ESTIMATE[3] for ESTIMATE in ESTIMATES]) # COMPUTE THE VARIANCE OF THE DATA
        self.ESTIMATES = ESTIMATES # SET THE ESTIMATES OF THE LINEAR DISCRIMINANT ANALYSIS MODEL

    # PREDICT: PREDICTS THE LABELS OF THE INPUT DATA.
    def PREDICT(self, X):
        assert self.ESTIMATES is not None, "FIT THE MODEL BEFORE USING IT TO PREDICT" # ASSERT THAT THE MODEL HAS BEEN FITTED
        BAYES_PROBABILITIES = [] # INITIALIZE THE BAYES PROBABILITIES LIST
        for ESTIMATE in self.ESTIMATES: # ITERATE THROUGH THE ESTIMATES
            PI = ESTIMATE[1] # GET THE PROBABILITY OF THE CLASS
            MEAN = ESTIMATE[2] # GET THE MEAN OF THE CLASS
            VARIANCE = ESTIMATE[3] # GET THE VARIANCE OF THE CLASS
            LOG_VARIANCE = np.log(VARIANCE) # COMPUTE THE LOG VARIANCE OF THE CLASS
            SIGMA_INV = inv(LOG_VARIANCE) # COMPUTE THE INVERSE OF THE LOG VARIANCE OF THE CLASS
            BAYES_PROBS = [] # INITIALIZE THE BAYES PROBABILITIES LIST
            for ROW in X: # ITERATE THROUGH THE ROWS OF THE INPUT DATA
                _X = ROW.reshape(-1,1) # RESHAPE THE ROW
                BAYES_PROB = (-.5 * multi_dot([(_X-MEAN).T,SIGMA_INV,(_X-MEAN)])[0][0]) - (.5 * np.log(det(LOG_VARIANCE))) + np.log(PI) # COMPUTE THE BAYES PROBABILITY OF THE ROW
                BAYES_PROBS.append(BAYES_PROB) # ADD THE BAYES PROBABILITY TO THE BAYES PROBABILITIES LIST
            BAYES_PROBABILITIES.append(np.array(BAYES_PROBS).reshape(-1,1)) # ADD THE BAYES PROBABILITIES TO THE BAYES PROBABILITIES LIST
        INDICES_OF_HIGHEST_PROB = np.argmax(np.concatenate(BAYES_PROBABILITIES,axis=1),axis=1) # GET THE INDICES OF THE HIGHEST PROBABILITIES
        PREDICTIONS = [self.ESTIMATES[IDX][0] for IDX in INDICES_OF_HIGHEST_PROB] # GET THE PREDICTIONS
        return np.array(PREDICTIONS) # RETURN THE PREDICTIONS