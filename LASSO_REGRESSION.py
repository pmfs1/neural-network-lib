import numpy as np

# LASSO_REGRESSION: IMPLEMENTS THE LASSO REGRESSION MODEL. WHICH IS A REGRESSION ANALYSIS METHOD THAT PERFORMS BOTH VARIABLE SELECTION AND REGULARIZATION IN ORDER TO ENHANCE THE PREDICTION ACCURACY AND INTERPRETABILITY OF THE RESULTING STATISTICAL MODEL. THE LASSO REGRESSION MODEL IS PARTICULARLY USEFUL TO ALLEVIATE THE PROBLEM OF MULTICOLLINEARITY IN LINEAR REGRESSION, WHICH COMMONLY OCCURS IN MODELS WITH LARGE NUMBERS OF PARAMETERS. MEANING, IT'S A LINEAR MODEL TRAINED WITH L1 PRIOR AS REGULARIZER.
class LASSO_REGRESSION:
    # INITIALIZES THE LASSO REGRESSION MODEL.
    def __init__(self, LEARNING_RATE=0.01, ITERATIONS=1000, L1_PENALITY=1):
        # LEARNING_RATE: IT'S THE HYPERPARAMETER THAT CONTROLS HOW MUCH TO CHANGE THE MODEL IN RESPONSE TO THE ESTIMATED ERROR EACH TIME THE MODEL WEIGHTS ARE UPDATED. IT MUST BE A POSITIVE FLOAT.
        self.LEARNING_RATE = LEARNING_RATE
        # ITERATIONS: IT'S THE HYPERPARAMETER THAT CONTROLS THE NUMBER OF TIMES TO RE-RUN THROUGH THE TRAINING DATA BEFORE STOPPING. IT MUST BE A POSITIVE INTEGER.
        self.ITERATIONS = ITERATIONS
        # L1_PENALITY: IT'S THE HYPERPARAMETER THAT CONTROLS THE AMOUNT OF PENALTY TO APPLY TO THE MODEL WEIGHTS. IT MUST BE A POSITIVE FLOAT. LARGER VALUES SPECIFY STRONGER PENALTY.
        self.L1_PENALITY = L1_PENALITY
        # WEIGHTS: IT'S THE PARAMETER THAT CORRESPONDS TO THE WEIGHTS OF THE LINEAR REGRESSION MODEL.
        self.WEIGHTS = None
        # BIAS: IT'S THE PARAMETER THAT CORRESPONDS TO THE BIAS OF THE LINEAR REGRESSION MODEL.
        self.BIAS = 0

    # FIT(): FITS THE LASSO REGRESSION MODEL TO THE TRAINING DATA
    def FIT(self, X, Y):
        # CALCULATE THE WEIGHTS OF THE LINEAR REGRESSION MODEL.
        self.WEIGHTS = np.zeros(X.shape[1])
        for _ in range(self.ITERATIONS):
            # CALCULATE THE PREDICTIONS OF THE LINEAR REGRESSION MODEL.
            Y_PRED = self.PREDICT(X)
            # CALCULATE THE DERIVATIVE OF THE WEIGHTS.
            DERIVATIVE_WEIGHTS = np.zeros(X.shape[1])
            for J in range(X.shape[1]):
                if self.WEIGHTS[J] > 0:
                    DERIVATIVE_WEIGHTS[J] = (-2 * X[:, J].dot(Y - Y_PRED) +
                                             self.L1_PENALITY) / X.shape[0]
                else:
                    DERIVATIVE_WEIGHTS[J] = (-2 * X[:, J].dot(Y - Y_PRED) -
                                             self.L1_PENALITY) / X.shape[0]
            # UPDATE THE WEIGHTS OF THE LINEAR REGRESSION MODEL.
            self.WEIGHTS -= self.LEARNING_RATE * DERIVATIVE_WEIGHTS
            DERIVATIVE_BIAS = -2 * np.sum(Y - Y_PRED) / X.shape[0]
            # UPDATE THE BIAS OF THE LINEAR REGRESSION MODEL.
            self.BIAS -= self.LEARNING_RATE * DERIVATIVE_BIAS

    # PREDICT(): PREDICTS THE LABELS OF THE TRAINING DATA.
    def PREDICT(self, X):
        # RETURNS THE PREDICTIONS OF THE LINEAR REGRESSION MODEL.
        return X.dot(self.WEIGHTS) + self.BIAS